<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Tim Hopper</title><link>https://tdhopper.com/tags/python/</link><description>Recent content in Python on Tim Hopper</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 17 Oct 2024 12:00:16 -0400</lastBuildDate><atom:link href="https://tdhopper.com/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Good programming languages are nice but not vital</title><link>https://tdhopper.com/blog/good-programming-languages-are-nice-but-not-vital/</link><pubDate>Wed, 03 Apr 2024 11:46:00 +0000</pubDate><guid>https://tdhopper.com/blog/good-programming-languages-are-nice-but-not-vital/</guid><description>&lt;img src="https://tdhopper.com/images/complaining.png" alt="Featured image of post Good programming languages are nice but not vital" />&lt;blockquote>
&lt;p>When someone says, “I want a programming language in which I need only say what I wish done,” give him a lollipop. (Alan Perlis, &lt;a class="link" href="https://cpsc.yale.edu/epigrams-programming" target="_blank" rel="noopener"
>Epigrams in Programming&lt;/a>)&lt;/p>
&lt;/blockquote>
&lt;p>People love to talk trash about programming languages on Twitter. Every day there&amp;rsquo;s a new viral tweet &lt;a class="link" href="https://x.com/holdenmatt/status/1774866242282672365?s=20" target="_blank" rel="noopener"
>about&lt;/a> &lt;a class="link" href="https://twitter.com/markopolojarvi/status/1753668713671475288?s=20" target="_blank" rel="noopener"
>the&lt;/a> &lt;a class="link" href="https://twitter.com/nominalthoughts/status/1750431818883694935?s=20" target="_blank" rel="noopener"
>inadequacies&lt;/a> &lt;a class="link" href="https://twitter.com/andrewwhite01/status/1734707815145422943?s=20" target="_blank" rel="noopener"
>of&lt;/a> &lt;a class="link" href="https://twitter.com/Josh_Merfeld/status/1701563560315547807?s=20" target="_blank" rel="noopener"
>Python&lt;/a>.&lt;/p>
&lt;p>I have worked with many programming languages and studied others in school, but I&amp;rsquo;ve spent most of the last ten years deep into Python. Of course, Python has warts and wrinkles; I&amp;rsquo;m intimately familiar with many of them! At the same time, people worldwide effectively use Python to solve all kinds of problems. As it turns out, many common frustrations can be set aside with a little effort (e.g., by integrating modern tooling like &lt;a class="link" href="https://github.com/astral-sh/ruff" target="_blank" rel="noopener"
>Ruff&lt;/a>).&lt;/p>
&lt;p>I&amp;rsquo;m regularly convinced that Brian Kernighan knew everything there is to know about software engineering practice, and he wrote it down before I was born in 1986. He doesn&amp;rsquo;t miss the mark in his &lt;a class="link" href="https://archive.org/details/programming-style" target="_blank" rel="noopener"
>1979 paper with Plauger&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>&amp;hellip;many people try to excuse badly written programs by blaming inadequacies of the language that must be used. We have seen repeatedly that even Fortran can be tamed with proper discipline. The presence of bad features is not an invitation to use them, nor is the absence of good features an excuse to avoid simulating them as cleanly as possible. Good languages are nice, but not vital.&lt;/p>
&lt;/blockquote>
&lt;p>People forget that two of the top three most visited websites (Youtube and Facebook) were originally implemented in PHP, a language rarely considered a Platonic ideal.&lt;/p>
&lt;p>Bjarne Stroustrup, creator of C++, says, &amp;ldquo;There are only two kinds of languages: the ones people complain about and the ones nobody uses.&amp;rdquo; He&amp;rsquo;s right, and I&amp;rsquo;m guessing we&amp;rsquo;ll never move entirely beyond that (even as language improvement continues). I, for one, am willing to embrace this and learn to do the best with the tools we have.&lt;/p></description></item><item><title>Announcing the Python Developer Tooling Handbook</title><link>https://tdhopper.com/blog/announcing-the-python-developer-tooling-handbook/</link><pubDate>Sat, 10 Feb 2024 16:31:16 +0000</pubDate><guid>https://tdhopper.com/blog/announcing-the-python-developer-tooling-handbook/</guid><description>&lt;img src="https://tdhopper.com/images/pydevtools-announcement.png" alt="Featured image of post Announcing the Python Developer Tooling Handbook" />&lt;p>I’ve been a professional Python developer for over a decade. Like many Python developers, I’ve faced the many challenges of Python packaging and dependency management. I’ve also come to love helping developers find the right tools to make their work easier and more productive.&lt;/p>
&lt;p>I&amp;rsquo;m excited to announce that I&amp;rsquo;m writing the &lt;a class="link" href="https://pydevtools.com/" target="_blank" rel="noopener"
>Python Developer Tooling Handbook&lt;/a>, a free
ebook on Python developer tooling. This handbook covers a wide range of topics,
including build tools, linting, formatting, dependency management, virtual environments,
and more.&lt;/p>
&lt;p>The book is currently a work in progress, and I&amp;rsquo;m excited to share it with you when it&amp;rsquo;s
ready. If you want to be notified as soon as it&amp;rsquo;s released, please consider signing up
for my mailing list &lt;a class="link" href="https://buttondown.email/pdth?tag=github" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/p></description></item><item><title>Code Review Guidelines for Data Science Teams</title><link>https://tdhopper.com/blog/code-review-guidelines/</link><pubDate>Fri, 03 Dec 2021 15:37:00 +0000</pubDate><guid>https://tdhopper.com/blog/code-review-guidelines/</guid><description>&lt;img src="https://tdhopper.com/images/code-review.png" alt="Featured image of post Code Review Guidelines for Data Science Teams" />&lt;p>Over the last 6 years, I&amp;rsquo;ve been able to help the teams I have been part of
develop guidelines for code review. Many teams require &amp;ldquo;code review&amp;rdquo; without
putting any effort into establishing a common understanding of what that
means. This post is adapted from proposed guidelines I prepared for one of my
teams. Of course, you don&amp;rsquo;t have to adopt &lt;em>my&lt;/em> guidelines for review, but I
would encourage your team to set aside some time to make sure you all mean the
same thing by &amp;ldquo;code review&amp;rdquo;.&lt;/p>
&lt;h2 id="what-is-a-code-review-for">What is a code review for?
&lt;/h2>&lt;p>Code review has multiple benefits and objectives including:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Code correctness&lt;/strong> : someone seeing your code with fresh eyes may help uncover bugs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Code familiarity&lt;/strong> : reading one another&amp;rsquo;s code keeps everyone familiar with the codebase.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Design feedback&lt;/strong> : a constantly evolving code base is a fight against complexity; reviewers can guide one another on keeping the codebase coherent and maintainable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mutual learning&lt;/strong> : the reviewer and author will inevitably learn from one another.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Regression protection&lt;/strong> : future contributors to the code base have checks against breaking essential functionality; importantly, &lt;em>this reduces fear of making necessary improvements to the code&lt;/em>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-code-reviews-arent">What code reviews aren&amp;rsquo;t
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>An opportunity for the reviewer to impose their idiosyncrasies.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>An opportunity for the developer to push off responsibility (e.g. correctness) for their code to the reviewer.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>An opportunity to demand perfection (Per &lt;a class="link" href="https://google.github.io/eng-practices/review/reviewer/standard.html" target="_blank" rel="noopener"
>Google’s Code Review Guidelines&lt;/a>: &lt;em>A key point here is that there is no such thing as &amp;ldquo;perfect&amp;rdquo; code—there is only better code&lt;/em> ).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="opening-pull-requests">Opening Pull Requests
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>Take care to write informative commit messages. This helps your reviewer understand the decisions you made.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Consider your contribution in the broader context of the code base. Do you need to take extra steps to make the code healthier and manage complexity?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Keep pull requests short whenever possible. &lt;code>git --shortstat origin/main&lt;/code> will show you the size of your branch &amp;rsquo;s diff from main; under 400 lines changed is a great goal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Write a pull request description that sets your reviewer up for success by helping them understand what the PR intends to accomplish.&lt;/p>
&lt;ul>
&lt;li>If you have a particularly complex PR, consider doing a code walk-through with a reviewer first.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>New code should ordinarily come with new tests.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="reviewing-pull-requests">Reviewing Pull Requests
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>Have a positive, constructive, helpful attitude.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wait for continuous integration tasks to complete. Let the author resolve any test failures before beginning your review.&lt;/p>
&lt;ul>
&lt;li>As much as possible, configure your continuous integration to enforce your team&amp;rsquo;s style guidelines and look for line-level bugs. In Python, this might include running mypy, flake8, black, and isort. Automation like this has multiple benefits: they&amp;rsquo;re often better than humans at this task, they reduce cognative load on the reviewer, and they reduce interpersonal tension that results from interviewers nitpicking code.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Things to evaluate:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Does the code appear to do what it claims to do? (This requires you understanding what the code claims to do; you may need to ask the code author to write a better description.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Was the new code put in the right place?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Is the new code unnecessarily complex—or unnecessarily clever?&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it. &amp;quot; – Brian Kernighan&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Does the new code do all it can to avoid adding to the overall complexity of our codebase?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Did the author write tests for the new code?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Clarify when a comment is minor or not essential for merging (for example, preface with &amp;ldquo;Nit: &amp;ldquo;).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If a PR is too large for you to reasonably review, you can ask the author to split it into multiple PRs.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="additional-reading">Additional Reading
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;a class="link" href="https://google.github.io/eng-practices/review/reviewer/standard.html" target="_blank" rel="noopener"
>Google &amp;rsquo;s excellent guide to code review&lt;/a> (Note: CL=change list=pull request)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://github.com/joho/awesome-code-review/blob/master/readme.md" target="_blank" rel="noopener"
>Curated list of articles about code review&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://docs.gitlab.com/ee/development/code_review.html" target="_blank" rel="noopener"
>Gitlab &amp;rsquo;s Code Review Guidelines&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://www.michaelagreiler.com/code-review-best-practices/" target="_blank" rel="noopener"
>Proven Code Review Best Practices from Microsoft&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://github.com/thoughtbot/guides/tree/master/code-review" target="_blank" rel="noopener"
>Thoughtbot Code Review Guidelines&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://slack.engineering/how-about-code-reviews/" target="_blank" rel="noopener"
>Code reviews at Slack&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;small>
[Computers](https://flickr.com/photos/duanestorey/2721991488 "Computers") flickr photo by [Duane Storey](https://flickr.com/people/duanestorey) shared under a [Creative Commons (BY-NC-ND) license](https://creativecommons.org/licenses/by-nc-nd/2.0/)
&lt;/small></description></item><item><title>The Programming Book That Made My Career</title><link>https://tdhopper.com/blog/learning-python/</link><pubDate>Wed, 20 Jan 2021 13:58:16 +0000</pubDate><guid>https://tdhopper.com/blog/learning-python/</guid><description>&lt;img src="https://tdhopper.com/images/minimalist-landscape-with-mouse-and-snake.png" alt="Featured image of post The Programming Book That Made My Career" />&lt;p>On January 7, 2011, &lt;a class="link" href="https://twitter.com/tdhopper/status/23515755127508993" target="_blank" rel="noopener"
>I
tweeted&lt;/a>, &amp;ldquo;Trying to
learn Python. We&amp;rsquo;ll see if this keeps up once classes start.&amp;rdquo;&lt;/p>
&lt;p>On January 20, 2011, ten years ago today, I bought Mark Lutz&amp;rsquo;s &lt;a class="link" href="https://amzn.to/3sHDwXa" target="_blank" rel="noopener"
>Learning Python&lt;/a> from O&amp;rsquo;Reilly Books. Over the next month, I
read it on my Kindle on the Stairmaster at the school gym. It changed the
course of my adult life: since reading that book, I&amp;rsquo;ve written Python on more
days than I haven&amp;rsquo;t.&lt;/p>
&lt;p>Before discovering the data science Twitter community in late 2010, I&amp;rsquo;d only
heard of Python through another student researcher in my 2007
&lt;a class="link" href="https://www.nsf.gov/crssprgm/reu/" target="_blank" rel="noopener"
>REU,&lt;/a> who had used Python for some graphics
programming research. On Twitter, people like &lt;a class="link" href="https://twitter.com/hmason" target="_blank" rel="noopener"
>Hilary
Mason&lt;/a>, &lt;a class="link" href="https://twitter.com/JohnDCook" target="_blank" rel="noopener"
>John
Cook&lt;/a>, and &lt;a class="link" href="https://twitter.com/fonnesbeck" target="_blank" rel="noopener"
>Chris
Fonnesbeck&lt;/a> talked warmly about using Python
in their scientific work.&lt;/p>
&lt;p>In 2011, I was a first-year operations research student at North Carolina
State University, and I realized that I should pick up programming again to
improve my career prospects. I&amp;rsquo;d taught myself some PHP in high school (circa
2003). In undergrad, I did a computer science minor and learned a good bit of
C++ and did a lot of Mathematica scripting in my math coursework, but from
2008 to 2011, I basically didn&amp;rsquo;t program.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/tdhopper/status/132924915526533120" target="_blank" rel="noopener"
>I struggled to use
Python&lt;/a> in practice
for ML/scientific computing in those days before wheels (binary installs);
libraries like Scipy and Numpy required brittle compilation of C++ and Fortran
dependencies. During the summer of 2011, I gave up using Python (&lt;a class="link" href="https://twitter.com/tdhopper/status/73798291648811008" target="_blank" rel="noopener"
>after
segfaulting&lt;/a>
&lt;a class="link" href="https://orangedatamining.com/" target="_blank" rel="noopener"
>Orange&lt;/a>) for my internship at &lt;a class="link" href="https://en.wikipedia.org/wiki/Amazon_Robotics" target="_blank" rel="noopener"
>Kiva Systems&lt;/a> and dove into R, where
I could install packages more reliably and use
&lt;a class="link" href="https://ggplot2.tidyverse.org/" target="_blank" rel="noopener"
>ggplot2&lt;/a>.&lt;/p>
&lt;p>For some reason (probably because of Twitter), I returned to Python a year
later and used it to write my research code in grad school (despite my
advisor&amp;rsquo;s wishes that I use C++). &lt;a class="link" href="https://github.com/fonnesbeck/ScipySuperpack" target="_blank" rel="noopener"
>Scipy Superpack&lt;/a> for installing the
Scipy stack was invaluable (thankfully now replaced by Wheels and Conda).&lt;/p>
&lt;p>My experience with Python was a big reason I got hired at &lt;a class="link" href="https://www.rti.org/" target="_blank" rel="noopener"
>RTI International&lt;/a> when I left my PhD program in October. They were looking to reduce their SAS dependency (and costs) and wanted
people experienced with open-source tools. I taught my colleagues a &amp;ldquo;Python for
statisticians&amp;rdquo; seminar soon after joining RTI.&lt;/p>
&lt;p>From RTI, I joined Parsely, which was like a Python boot camp working with &lt;a class="link" href="https://amontalenti.com/" target="_blank" rel="noopener"
>Andrew Montalenti&lt;/a> and others. Parsely uses Python across
their full stack, and it was an eye-opening and educational year for me.&lt;/p>
&lt;p>Since then, I&amp;rsquo;ve worked at a variety of companies where I&amp;rsquo;ve been able to use
Python for training machine learning models, building machine learning
platforms, &lt;a class="link" href="https://dp.tdhopper.com" target="_blank" rel="noopener"
>writing Gibbs samplers for nonparametric Bayes&lt;/a>, building data engineering pipelines, software
testing, etc.&lt;/p>
&lt;p>I use Python almost every single day for work and a lot of personal projects.
I&amp;rsquo;ve been able &lt;a class="link" href="https://tdhopper.com/talks" >to speak&lt;/a> at 3 PyData conferences,
a Scipy conference, and a number &lt;a class="link" href="https://www.meetup.com/tripython/" target="_blank" rel="noopener"
>Triangle Python Users Groups&lt;/a>. I had a &lt;a class="link" href="https://github.com/python/cpython/pull/11847" target="_blank" rel="noopener"
>contribution merged into CPython in 2019&lt;/a> and have
contributed to many other open-source projects.&lt;/p>
&lt;p>I&amp;rsquo;m grateful to the countless people who have taught me (through tweets, code
reviews, conference talks, etc) about Python and the many who have built the
wonderful language with its incredible ecosystem of tools and packages that
enable me and others to do so many things.&lt;/p></description></item><item><title>Installing Python on Mohave with pyenv</title><link>https://tdhopper.com/blog/installing-python/</link><pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/installing-python/</guid><description>&lt;p>I use &lt;a class="link" href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener"
>pyenv&lt;/a> to manage Python versions on my Mac. I recently have gotten errors like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">WARNING: The Python sqlite3 extension was not compiled. Missing the SQLite3 lib?
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">zipimport.ZipImportError: can&amp;#39;t decompress data; zlib not available
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The solution seems to be setting &lt;code>LDFLAGS&lt;/code> and &lt;code>CPPFLAGS&lt;/code> to point to the sqlite3 and zlib libraries, e.g.:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">brew install sqlite3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">brew install zlib
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LDFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;-L/usr/local/opt/zlib/lib -L/usr/local/opt/sqlite/lib&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CPPFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;-I/usr/local/opt/zlib/include -I/usr/local/opt/sqlite/include&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pyenv install 3.7.0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Devops Empowered Data Science with Ansible</title><link>https://tdhopper.com/blog/ansible-talk/</link><pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/ansible-talk/</guid><description>&lt;p>I gave a talk at Scipy 2018 loosely based on my &lt;a class="link" href="https://tdhopper.com/blog/automating-python-with-ansible/" >Ansible tutorial&lt;/a>. Here are my slides:&lt;/p>
&lt;iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSHtiQKbpNvd902FzCqhzjZCbt4ldbPnolgSQfQbaPoQk0eweUng7Wkxjb5uDi942Ul0trl3s7C0yQ5/embed?start=false&amp;loop=false&amp;delayms=5000" frameborder="0" width="480" height="389" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">&lt;/iframe>
&lt;p>&lt;small>&lt;a class="link" href="https://drive.google.com/open?id=1nsgG2YjfE5yWGdsxfzgqDj4SS1isyOIzBUjNa-r8ly0" target="_blank" rel="noopener"
>Open in Google Docs&lt;/a>&lt;/small>&lt;/p>
&lt;p>And the video:&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/LKVtmGtT6qg"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div></description></item><item><title>Python Plotting for Exploratory Data Analysis</title><link>https://tdhopper.com/blog/python-plotting-for-exploratory-data-analysis/</link><pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/python-plotting-for-exploratory-data-analysis/</guid><description>&lt;p>Plotting is an essential component of data analysis. As a data scientist, I spend a significant amount of my time making simple plots to understand complex data sets (exploratory data analysis) and help others understand them (presentations).&lt;/p>
&lt;p>In particular, I make a lot of bar charts (including histograms), line plots (including time series), scatter plots, and density plots from data in Pandas data frames. I often want to facet these on various categorical variables and layer them on a common grid.&lt;/p>
&lt;p>To that end, I made &lt;a class="link" href="http://pythonplot.com/" target="_blank" rel="noopener"
>pythonplot.com&lt;/a>, a brief introduction to Python plotting libraries and a &amp;ldquo;rosetta stone&amp;rdquo; comparing how to use them. I also included comparison to &lt;a class="link" href="https://en.wikipedia.org/wiki/Ggplot2" title="Wikipedia Entry: ggplot2 - Wikipedia"
target="_blank" rel="noopener"
>ggplot2&lt;/a>, the R plotting library that I and many others consider a gold standard.&lt;/p></description></item><item><title>Parallelizing a Python Function for the Extremely Lazy</title><link>https://tdhopper.com/blog/parallelizing-a-python-function-for-the-extremely-lazy/</link><pubDate>Wed, 07 Jun 2017 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/parallelizing-a-python-function-for-the-extremely-lazy/</guid><description>&lt;p>Do you ever want to be able to run a Python function in parallel on a set of inputs? Have you ever gotten frustrated with the GIL, the multiprocessing library, or joblib?&lt;/p>
&lt;p>Try this:&lt;/p>
&lt;h2 id="install-python-fire-to-run-your-command-from-the-command-line">Install Python Fire to run your command from the command line
&lt;/h2>&lt;p>Install &lt;a class="link" href="https://github.com/google/python-fire" target="_blank" rel="noopener"
>Python Fire&lt;/a> with &lt;code>$ pip install fire&lt;/code>.&lt;/p>
&lt;p>Add this snippet to the bottom of your file:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if __name__ == &amp;#39;__main__&amp;#39;:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> import fire
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fire.Fire()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="install-gnu-parallel">Install GNU Parallel
&lt;/h2>&lt;p>&lt;code>$ brew install parallel&lt;/code> or &lt;code>$ sudo apt-get install parallel&lt;/code> may work for you. Otherwise, see &lt;a class="link" href="https://www.gnu.org/software/parallel/" target="_blank" rel="noopener"
>this&lt;/a>.&lt;/p>
&lt;h2 id="run-your-function-from-the-command-line">Run your function from the command line
&lt;/h2>&lt;p>&lt;code>$ parallel -j3 &amp;quot;python python_file.py function_name {1} &amp;quot; ::: input1 input2 input3 input4 input5&lt;/code>&lt;/p>
&lt;ul>
&lt;li>&lt;code>parallel&lt;/code> is the command for GNU Parallel.&lt;/li>
&lt;li>&lt;code>-j3&lt;/code> tells Parallel to run at most 3 processes at once.&lt;/li>
&lt;li>&lt;code>{1}&lt;/code> fills in each item after the &lt;code>:::&lt;/code> as an argument to the &lt;code>function_name&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h2 id="for-example">For example
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">(lazy) ~ $ cat python_file.py
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">from time import sleep
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">def function_name(arg1):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> print(&amp;#34;Starting to run with&amp;#34;, arg1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sleep(2)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> print(&amp;#34;Finishing to run with&amp;#34;, arg1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if __name__ == &amp;#39;__main__&amp;#39;:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> import fire
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fire.Fire()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(lazy) ~ $ parallel -j3 --lb &amp;#34;python -u python_file.py function_name {1} &amp;#34; ::: input1 input2 input3 input4 input5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Starting to run with input2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Starting to run with input1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Starting to run with input3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Finishing to run with input2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Finishing to run with input1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Finishing to run with input3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Starting to run with input4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Starting to run with input5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Finishing to run with input4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Finishing to run with input5
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I added &lt;code>--lb&lt;/code> and &lt;code>-u&lt;/code> to keep Python and Parallel from buffering the output so you can see it being run in parallel.&lt;/p></description></item><item><title>Automating Python with Ansible</title><link>https://tdhopper.com/blog/automating-python-with-ansible/</link><pubDate>Thu, 23 Mar 2017 15:11:00 +0000</pubDate><guid>https://tdhopper.com/blog/automating-python-with-ansible/</guid><description>&lt;p>I wrote &lt;a class="link" href="https://tdhopper.com/blog/data-scientists-need-more-automation/" >a few months back&lt;/a> about how data scientists need more automation. In
particular, I suggested that data scientists would be wise to learn more about
automated system configuration and automated deployments.&lt;/p>
&lt;p>In an attempt to take my own advice, I&amp;rsquo;ve finally been making myself learn
&lt;a class="link" href="https://www.ansible.com/" target="_blank" rel="noopener"
>Ansible&lt;/a>. It turns out that a great way to learn it
is to sit down and read through the docs, front to back; I commend that tactic
to you. I also put together this tutorial to walk through a practical example
of how a working data scientist might use this powerful tool.&lt;/p>
&lt;p>What follows is an Ansible guide that will take you from installing Ansible to
automatically deploying a long-running Python to a remote machine and running
it in a &lt;a class="link" href="https://conda.io/docs/using/envs.html" target="_blank" rel="noopener"
>Conda environment&lt;/a> using
&lt;a class="link" href="http://supervisord.org/" target="_blank" rel="noopener"
>supervisord&lt;/a>. It presumes your development machine
is on OS X and the remote machine is Debian-like; however, it shouldn&amp;rsquo;t
require too many changes to run it on other systems.&lt;/p>
&lt;p>I wrote this post in a Jupyter notebook with a Bash kernel. You can find the
notebook, Ansible files, and installation directions on &lt;a class="link" href="https://github.com/tdhopper/automating_python" target="_blank" rel="noopener"
>my
Github&lt;/a>.&lt;/p>
&lt;h2 id="ansible">Ansible
&lt;/h2>&lt;p>Ansible provides &amp;ldquo;human readable automation&amp;rdquo; for &amp;ldquo;app deployment&amp;rdquo; and
&amp;ldquo;configuration management&amp;rdquo;. Unlike tools like Chef, it doesn&amp;rsquo;t require an
agent to be running on remote machines. In short, it translates declarative
YAML files into shell commands and runs them on your machines over SSH.&lt;/p>
&lt;p>Ansible is backed by Red Hat and has a great
&lt;a class="link" href="https://www.ansible.com/" target="_blank" rel="noopener"
>website&lt;/a>.&lt;/p>
&lt;h2 id="installing-ansible-with-homebrew">Installing Ansible with Homebrew
&lt;/h2>&lt;p>First, you&amp;rsquo;ll need to &lt;a class="link" href="http://docs.ansible.com/ansible/intro_installation.html" target="_blank" rel="noopener"
>install
Ansible&lt;/a>. On a Mac, I
recommend doing this with &lt;a class="link" href="https://brew.sh/" target="_blank" rel="noopener"
>Homebrew&lt;/a>.&lt;/p>
&lt;pre>&lt;code>brew install ansible
Warning: ansible-2.1.0.0 already installed
Warning: You are using OS X 10.12.
We do not provide support for this pre-release version.
You may encounter build failures or other breakages.
&lt;/code>&lt;/pre>
&lt;h2 id="quickstart">Quickstart
&lt;/h2>&lt;p>Soon, I&amp;rsquo;ll show you how to put write an Ansible YAML file. However, Ansible
also allows you specify tasks from the command line.&lt;/p>
&lt;p>Here&amp;rsquo;s how we could use Ansible ping our local host:&lt;/p>
&lt;pre>&lt;code>ansible -i 'localhost,' -c local -m ping all
ansible -i 'localhost,' -c local -m ping all
localhost | SUCCESS =&amp;gt; {
&amp;quot;changed&amp;quot;: false,
&amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>This command calls ansible and tells it:&lt;/p>
&lt;ul>
&lt;li>To use &lt;code>localhost&lt;/code> as it&amp;rsquo;s inventory (&lt;code>-i&lt;/code>). Inventory is Ansible speak for machine or machines you want to be able to run commands on.&lt;/li>
&lt;li>To connect (&lt;code>-c&lt;/code>) locally (&lt;code>local&lt;/code>) instead of over SSH.&lt;/li>
&lt;li>To run the &lt;a class="link" href="http://docs.ansible.com/ansible/ping_module.html" target="_blank" rel="noopener"
>&lt;code>ping&lt;/code> module&lt;/a> (&lt;code>-m&lt;/code>) to test the connection.&lt;/li>
&lt;li>To run the command on &lt;code>all&lt;/code> hosts in the inventory (in this case, our inventory is just the &lt;code>localhost&lt;/code>).&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://web.archive.org/web/20170330023127/http://www.mechanicalfish.net/start-learning-ansible-with-one-line-and-no-files/" target="_blank" rel="noopener"
>Michael Booth&lt;/a> has a
&lt;a class="link" href="https://web.archive.org/web/20170330023127/http://www.mechanicalfish.net/start-learning-ansible-with-one-line-and-no-files/" target="_blank" rel="noopener"
>post&lt;/a> that goes into more detail about
this command.&lt;/p>
&lt;p>Behind the scenes, Ansible is turning this &lt;code>-m ping&lt;/code> command into shell
commands. (Try running with the &lt;code>-vvv&lt;/code> flag to see what&amp;rsquo;s happening behind the
scenes.) It can also execute arbitrary commands; by default, it&amp;rsquo;ll use the
Bourne shell &lt;code>sh&lt;/code>.&lt;/p>
&lt;pre>&lt;code>ansible all -i 'localhost, ' -c local -a &amp;quot;/bin/echo hello&amp;quot;
&lt;/code>&lt;/pre>
&lt;h2 id="setting-up-an-ansible-inventory">Setting up an Ansible Inventory
&lt;/h2>&lt;p>Instead of specifying our inventory with the &lt;code>-i&lt;/code> flag each time, we should
specify an Ansible inventory file. This file is a text file specifying
machines you have SSH access to; you can also group machines under bracketed
headings. For example:&lt;/p>
&lt;pre>&lt;code>mail.example.com
[webservers]
foo.example.com
bar.example.com
[dbservers]
one.example.com
two.example.com
three.example.com
&lt;/code>&lt;/pre>
&lt;p>Ansible has to be able to connect to these machines over SSH, so you will
likely need to have relevant entries in your &lt;a class="link" href="http://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/" target="_blank" rel="noopener"
>&lt;code>.ssh/config&lt;/code> file&lt;/a>.&lt;/p>
&lt;p>By default, the Ansible CLI will look for a system-wide Ansible inventory file
in &lt;code>/etc/ansible/hosts&lt;/code>. You can also specify an alternative path for an
intentory file with the &lt;code>-i&lt;/code> flag.&lt;/p>
&lt;p>For this tutorial, I&amp;rsquo;d like to have an inventory file specific to the project
directory without having to specify it each time we call Ansible. We can do
this by creating a file called &lt;code>./ansible.cfg&lt;/code> and set the name of our local
inventory file:&lt;/p>
&lt;pre>&lt;code>cat ./ansible.cfg
cat ./ansible.cfg
[defaults]
inventory = ./hosts
&lt;/code>&lt;/pre>
&lt;p>You can check that Ansible is picking up your config file by running &lt;code>ansible --version&lt;/code>.&lt;/p>
&lt;pre>&lt;code>ansible --version
ansible --version
ansible 2.1.0.0
config file = /Users/tdhopper/repos/automating_python/ansible.cfg
configured module search path = Default w/o overrides
&lt;/code>&lt;/pre>
&lt;p>For this example, I just have one host, a &lt;a class="link" href="https://www.digitalocean.com/" target="_blank" rel="noopener"
>Digital Ocean
VPS&lt;/a>. To run the examples below, you should
create a VPS instance on Digital Ocean, &lt;a class="link" href="https://amazonlightsail.com" target="_blank" rel="noopener"
>Amazon&lt;/a>,
or elsewhere; you&amp;rsquo;ll want to configure it for &lt;a class="link" href="https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys--2" target="_blank" rel="noopener"
>passwordless authentication&lt;/a>. I have an entry like this in my &lt;code>~/.ssh/hosts&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>Host digitalocean
HostName 45.55.395.23
User root
Port 22
IdentityFile /Users/tdhopper/.ssh/id_rsa
ForwardAgent yes
&lt;/code>&lt;/pre>
&lt;p>and my intentory file (&lt;code>~/hosts&lt;/code>) is just&lt;/p>
&lt;pre>&lt;code>digitalocean
&lt;/code>&lt;/pre>
&lt;p>Before trying ansible, you should ensure that you can connect to this host:&lt;/p>
&lt;pre>&lt;code>ssh digitalocean echo 1
ssh digitalocean echo 1
1
&lt;/code>&lt;/pre>
&lt;p>Now I can verify that Ansible can connect to my machine by running the ping
command.&lt;/p>
&lt;pre>&lt;code>ansible all -m ping
ansible all -m ping
digitalocean | SUCCESS =&amp;gt; {
&amp;quot;changed&amp;quot;: false,
&amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>We told Ansible to run this command on &lt;code>all&lt;/code> specified hosts in the inventory.
It found our inventory by loading the &lt;code>ansible.cfg&lt;/code> which specified &lt;code>./hosts&lt;/code>
as the inventory file.&lt;/p>
&lt;p>It&amp;rsquo;s possible that this will fail for you even if you can SSH into the
machine. If the error is something like &lt;code>/bin/sh: 1: /usr/bin/python: not found&lt;/code>, this is because your VPS doesn&amp;rsquo;t have Python installed on it. You can
&lt;a class="link" href="http://stackoverflow.com/questions/32429259/ansible-fails-with-bin-sh-1-usr-bin-python-not-found" target="_blank" rel="noopener"
>install it with Ansible&lt;/a>, but you may just want to
manually run &lt;code>sudo apt-get -y install python&lt;/code> on the VPS to get started.&lt;/p>
&lt;h2 id="writing-our-first-playbook">Writing our first Playbook
&lt;/h2>&lt;p>While adhoc commands will often be useful, the real power of Ansible comes
from creating repeatable sets of instructions called
&lt;a class="link" href="http://docs.ansible.com/ansible/playbooks.html" target="_blank" rel="noopener"
>Playbooks&lt;/a>.&lt;/p>
&lt;p>A playbook contains a list of &amp;ldquo;plays&amp;rdquo;. Each play specifies a set of tasks to
be run and which hosts to run them on. A &amp;ldquo;task&amp;rdquo; is a call to an Ansible
module, like the &amp;ldquo;ping&amp;rdquo; module we&amp;rsquo;ve already seen. Ansible &lt;a class="link" href="http://docs.ansible.com/ansible/list_of_all_modules.html" target="_blank" rel="noopener"
>comes packaged
with about 1000
modules&lt;/a> for all
sorts of use cases. You can also extend it with your own
&lt;a class="link" href="http://docs.ansible.com/ansible/dev_guide/developing_modules.html" target="_blank" rel="noopener"
>modules&lt;/a>
and &lt;a class="link" href="http://docs.ansible.com/ansible/playbooks_roles.html#roles" target="_blank" rel="noopener"
>roles&lt;/a>.&lt;/p>
&lt;p>Our first playbook will just execute the ping module on all our hosts. It&amp;rsquo;s a
playbook with a single play comprised of a single task.&lt;/p>
&lt;pre>&lt;code>cat ping.yml
cat ping.yml
---
- hosts: all
tasks:
- name: ping all hosts
ping:
&lt;/code>&lt;/pre>
&lt;p>We can run our playbook with the &lt;code>ansible-playbook&lt;/code> command.&lt;/p>
&lt;pre>&lt;code>ansible-playbook ping.yml
ansible-playbook ping.yml
____________
&amp;lt; PLAY [all] &amp;gt;
------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
______________
&amp;lt; TASK [setup] &amp;gt;
--------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
ok: [digitalocean]
_______________________
&amp;lt; TASK [ping all hosts] &amp;gt;
-----------------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
ok: [digitalocean]
____________
&amp;lt; PLAY RECAP &amp;gt;
------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
digitalocean : ok=2 changed=0 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;p>You might wonder why there are cows on your screen. You can find out
&lt;a class="link" href="https://michaelheap.com/cowsay-and-ansible/" target="_blank" rel="noopener"
>here&lt;/a>. However, the important
thing is that our task was executed and returned successfully.&lt;/p>
&lt;p>We can override the hosts list for the play with the &lt;code>-i&lt;/code> flag to see what the
output looks like when Ansible fails to run the play because it can&amp;rsquo;t find the
host.&lt;/p>
&lt;p>Let&amp;rsquo;s work now on installing the dependencies for our Python project.&lt;/p>
&lt;h2 id="installing-supervisord">Installing supervisord
&lt;/h2>&lt;p>&amp;ldquo;Supervisor is a client/server system that allows its users to monitor and
control a number of processes on UNIX-like operating systems.&amp;rdquo; We&amp;rsquo;ll use it to
run and monitor our Python process.&lt;/p>
&lt;p>On a Debian-like system, we can install it with APT. In the Ansible DSL that&amp;rsquo;s
just:&lt;/p>
&lt;pre>&lt;code>- name: Install supervisord
sudo: yes
apt:
name: supervisor
state: present
update_cache: yes
&lt;/code>&lt;/pre>
&lt;p>You can read more about the &lt;a class="link" href="http://docs.ansible.com/ansible/apt_module.html" target="_blank" rel="noopener"
>apt module
here&lt;/a>.&lt;/p>
&lt;p>Once we have it installed, we can start it with this task:&lt;/p>
&lt;pre>&lt;code>- name: Start supervisord
sudo: yes
service:
name: &amp;quot;supervisor&amp;quot;
state: running
enabled: yes
&lt;/code>&lt;/pre>
&lt;p>This uses the &lt;a class="link" href="http://docs.ansible.com/ansible/service_module.html" target="_blank" rel="noopener"
>service&lt;/a>
module.&lt;/p>
&lt;p>We could add these these tasks to a playbook file (like ping.yml), but what
maybe we will want to share it among multiple playbooks? For this, Ansible has
a construct called
&lt;a class="link" href="http://docs.ansible.com/ansible/playbooks_roles.html" target="_blank" rel="noopener"
>Roles&lt;/a>. A role is a
collection of &amp;ldquo;variable values, certain tasks, and certain handlers – or just
one or more of these things&amp;rdquo;. (You can learn more about variables and handlers
in the Ansible docs.)&lt;/p>
&lt;p>Roles are organized as subfolders of a folder called &amp;ldquo;Roles&amp;rdquo; in the working
directory. The rapid proliferation of folders in Ansible organization can be
overwhelming, but a very simple rule is just a file called &lt;code>main.yml&lt;/code> nestled
several folders deep. In our case, it&amp;rsquo;s in
&lt;code>./roles/supervisor/tasks/main.yml&lt;/code>.&lt;/p>
&lt;p>Check out &lt;a class="link" href="http://docs.ansible.com/ansible/playbooks_roles.html#roles" target="_blank" rel="noopener"
>the
docs&lt;/a> to learn
more about role organization.&lt;/p>
&lt;p>Here&amp;rsquo;s what our role looks like:&lt;/p>
&lt;pre>&lt;code>cat ./roles/supervisor/tasks/main.yml
cat ./roles/supervisor/tasks/main.yml
---
- name: Install supervisord
become: true
apt:
name: supervisor
state: present
update_cache: yes
tags:
supervisor
- name: Start supervisord
become: true
service:
name: &amp;quot;supervisor&amp;quot;
state: running
enabled: yes
tags:
supervisor
&lt;/code>&lt;/pre>
&lt;p>Note that I added &lt;code>tags:&lt;/code> to the task definitions.
&lt;a class="link" href="http://docs.ansible.com/ansible/playbooks_tags.html" target="_blank" rel="noopener"
>Tags&lt;/a> just allow you to
run a portion of a playbook instead of the whole thing with the &lt;code>--tags&lt;/code> flag
for &lt;code>ansible-playbook&lt;/code>.&lt;/p>
&lt;p>Now that we have the supervisor install encapsulated in a role, we can write a
simple playbook to run the role.&lt;/p>
&lt;pre>&lt;code>cat supervisor.yml
cat supervisor.yml
---
- hosts: digitalocean
roles:
- role: supervisor
ansible-playbook supervisor.yml
ansible-playbook supervisor.yml
_____________________
&amp;lt; PLAY [digitalocean] &amp;gt;
---------------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
______________
&amp;lt; TASK [setup] &amp;gt;
--------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
ok: [digitalocean]
_________________________________________
&amp;lt; TASK [supervisor : Install supervisord] &amp;gt;
-----------------------------------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
changed: [digitalocean]
_______________________________________
&amp;lt; TASK [supervisor : Start supervisord] &amp;gt;
---------------------------------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
changed: [digitalocean]
____________
&amp;lt; PLAY RECAP &amp;gt;
------------
\ ^__^
\ (oo)\_______
(__)\ )\/\
||----w |
|| ||
digitalocean : ok=3 changed=2 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;h2 id="installing-conda-with-ansible-galaxy">Installing Conda with Ansible Galaxy
&lt;/h2>&lt;p>Next we want to ensure that Conda installed on our system. We could write our
own role to follow the &lt;a class="link" href="https://www.continuum.io/downloads" target="_blank" rel="noopener"
>recommended
process&lt;/a>. However, Ansible has a helpful
tool to help us avoid reinventing the wheel by allowing users to share roles;
this is called &lt;a class="link" href="https://galaxy.ansible.com/" target="_blank" rel="noopener"
>Ansible Galaxy&lt;/a>.&lt;/p>
&lt;p>You can search the Galaxy website for
&lt;a class="link" href="https://galaxy.ansible.com/list#/roles?page=1&amp;amp;page_size=10&amp;amp;autocomplete=miniconda" target="_blank" rel="noopener"
>miniconda&lt;/a>
and see that a handful of roles for installing Miniconda exist. I liked &lt;a class="link" href="https://galaxy.ansible.com/andrewrothstein/miniconda/" target="_blank" rel="noopener"
>this
one&lt;/a>.&lt;/p>
&lt;p>We can install the role locally using the &lt;code>ansible-galaxy&lt;/code> command line tool.&lt;/p>
&lt;pre>&lt;code>ansible-galaxy install -f andrewrothstein.miniconda
&lt;/code>&lt;/pre>
&lt;p>You can have the role installed wherever you want (run &lt;code>ansible-galaxy install --help&lt;/code> to see how, but by default they&amp;rsquo;ll go to
&lt;code>/usr/local/etc/ansible/roles/&lt;/code>.&lt;/p>
&lt;pre>&lt;code>ls -lh /usr/local/etc/ansible/roles/andrewrothstein.miniconda
ls -lh /usr/local/etc/ansible/roles/andrewrothstein.miniconda
total 32
-rw-rw-r-- 1 tdhopper admin 1.1K Jan 16 16:52 LICENSE
-rw-rw-r-- 1 tdhopper admin 666B Jan 16 16:52 README.md
-rw-rw-r-- 1 tdhopper admin 973B Jan 16 16:52 circle.yml
drwxrwxr-x 3 tdhopper admin 102B Mar 21 11:33 defaults
drwxrwxr-x 3 tdhopper admin 102B Mar 21 11:33 handlers
drwxrwxr-x 4 tdhopper admin 136B Mar 21 11:33 meta
drwxrwxr-x 3 tdhopper admin 102B Mar 21 11:33 tasks
drwxrwxr-x 3 tdhopper admin 102B Mar 21 11:33 templates
-rw-rw-r-- 1 tdhopper admin 57B Jan 16 16:52 test.yml
drwxrwxr-x 3 tdhopper admin 102B Mar 21 11:33 vars
&lt;/code>&lt;/pre>
&lt;p>You can look at the &lt;code>tasks/main.yml&lt;/code> to see the core logic of installing
Miniconda. It has tasks to download the installer, run the installer, delete
the installer, run &lt;code>conda update conda&lt;/code>, and make &lt;code>conda&lt;/code> the default system
Python.&lt;/p>
&lt;pre>&lt;code>cat /usr/local/etc/ansible/roles/andrewrothstein.miniconda/tasks/main.yml
/main.ymllocal/etc/ansible/roles/andrewrothstein.miniconda/tasks
---
# tasks file for miniconda
- name: download installer...
become: yes
become_user: root
get_url:
url: '{{miniconda_installer_url}}'
dest: /tmp/{{miniconda_installer_sh}}
timeout: '{{miniconda_timeout_seconds}}'
checksum: '{{miniconda_checksum}}'
mode: '0755'
- name: installing....
become: yes
become_user: root
command: /tmp/{{miniconda_installer_sh}} -b -p {{miniconda_parent_dir}}/{{miniconda_name}}
args:
creates: '{{miniconda_parent_dir}}/{{miniconda_name}}'
- name: deleting installer...
become: yes
become_user: root
when: miniconda_cleanup
file:
path: /tmp/{{miniconda_installer_sh}}
state: absent
- name: link miniconda...
become: yes
become_user: root
file:
dest: '{{miniconda_parent_dir}}/miniconda'
src: '{{miniconda_parent_dir}}/{{miniconda_name}}'
state: link
- name: conda updates
become: yes
become_user: root
command: '{{miniconda_parent_dir}}/miniconda/bin/conda update -y --all'
- name: make system default python etc...
when: miniconda_make_sys_default
become: yes
become_user: root
with_items:
- etc/profile.d/miniconda.sh
template:
src: '{{item}}.j2'
dest: /{{item}}
mode: 0644
&lt;/code>&lt;/pre>
&lt;h3 id="overriding-ansible-variables">Overriding Ansible Variables
&lt;/h3>&lt;p>Once a role is installed locally, you can add it to a play just like you can
with roles you wrote. Installing Miniconda is now as simple as:&lt;/p>
&lt;pre>&lt;code> roles:
- role: andrewrothstein.miniconda
&lt;/code>&lt;/pre>
&lt;p>Before we add that to a playbook, I want to customize &lt;em>where&lt;/em> miniconda is
installed. If you look back at the &lt;code>main.yml&lt;/code> file above, you see a bunch of
things surrounded in double brackets. These are variables (in the &lt;a class="link" href="http://jinja.pocoo.org/docs/2.9/" target="_blank" rel="noopener"
>Jinja2
template language&lt;/a>). From the play, we can
see that Miniconda will be installed at
&lt;code>{{miniconda_parent_dir}}/{{miniconda_name}}&lt;/code>. The role defines these
variables in &lt;code>/andrewrothstein.miniconda/defaults/main.yml&lt;/code>. We can override
the default variables by specifying them in our play.&lt;/p>
&lt;p>A play to install miniconda could look like this:&lt;/p>
&lt;pre>&lt;code>---
- hosts: digitalocean
vars:
conda_folder_name: miniconda
conda_root: /root
roles:
- role: andrewrothstein.miniconda
miniconda_parent_dir: &amp;quot;{{ conda_root }}&amp;quot;
miniconda_name: &amp;quot;{{ conda_folder_name }}&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>I added this to
&lt;a class="link" href="https://github.com/tdhopper/automating_python/blob/master/playbook.yml" target="_blank" rel="noopener"
>&lt;code>playbook.yml&lt;/code>&lt;/a>.&lt;/p>
&lt;p>We now know how to use Ansible to start and run supervisord and to install
Miniconda. Let&amp;rsquo;s see how to use it to deploy and start our application.&lt;/p>
&lt;h2 id="deploy-python-application">Deploy Python Application
&lt;/h2>&lt;p>There are countless ways to deploy a Python application. We&amp;rsquo;re going to see
how to use Ansible to deploy from Github.&lt;/p>
&lt;p>I created a little project called
&lt;a class="link" href="https://github.com/tdhopper/long_running_python_process" target="_blank" rel="noopener"
>long_running_python_application&lt;/a>.
It has a
&lt;a class="link" href="https://github.com/tdhopper/long_running_python_process/blob/master/main.py" target="_blank" rel="noopener"
>&lt;code>main.py&lt;/code>&lt;/a>
that writes a log line to stdout every 30 seconds; that&amp;rsquo;s it. It also includes
a &lt;a class="link" href="https://github.com/tdhopper/long_running_python_process/blob/master/environment.yml" target="_blank" rel="noopener"
>Conda environment
file&lt;/a>
specifying the dependencies and &lt;a class="link" href="https://github.com/tdhopper/long_running_python_process/blob/master/run.sh" target="_blank" rel="noopener"
>a shell
script&lt;/a>
that activates the environment and runs the program.&lt;/p>
&lt;p>We&amp;rsquo;re going to use Ansible to&lt;/p>
&lt;ol>
&lt;li>Clone the repository into our remote machine.&lt;/li>
&lt;li>Create a Conda environment based on the environment.yml file.&lt;/li>
&lt;li>Create a supervisord file for running the program.&lt;/li>
&lt;li>Start the supervisord job.&lt;/li>
&lt;/ol>
&lt;h3 id="clone-the-repository">Clone the repository
&lt;/h3>&lt;p>Cloning a repository with Ansible is easy. We just use the &lt;a class="link" href="http://docs.ansible.com/ansible/git_module.html" target="_blank" rel="noopener"
>&lt;code>git&lt;/code>
module&lt;/a>. This play will clone
the repo into the specified directory. The &lt;code>update: yes&lt;/code> flag tells Ansible to
update the repository from the remote if it has already been cloned.&lt;/p>
&lt;pre>&lt;code>---
- hosts: digitalocean
vars:
project_repo: git://github.com/tdhopper/long_running_python_process.git
project_location: /srv/long_running_python_process
tasks:
- name: Clone project code.
git:
repo: &amp;quot;{{ project_repo }}&amp;quot;
dest: &amp;quot;{{ project_location }}&amp;quot;
update: yes
&lt;/code>&lt;/pre>
&lt;h3 id="creating-the-conda-environment">Creating the Conda Environment
&lt;/h3>&lt;p>Since we&amp;rsquo;ve now installed conda and cloned the repository with an
&lt;code>environment.yml&lt;/code> file, we just need to run &lt;code>conda env update&lt;/code> from the
directory containing the environment spec. Here&amp;rsquo;s a play to do that:&lt;/p>
&lt;pre>&lt;code>---
- hosts: digitalocean
vars:
project_location: /srv/long_running_python_process
tasks:
- name: Create Conda environment from project environment file.
command: &amp;quot;{{conda_root}}/{{conda_folder_name}}/bin/conda env update&amp;quot;
args:
chdir: &amp;quot;{{ project_location }}&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>It uses the &lt;a class="link" href="http://docs.ansible.com/ansible/command_module.html" target="_blank" rel="noopener"
>&lt;code>command&lt;/code>
module&lt;/a> which just
executes a shell command in the desired directory.&lt;/p>
&lt;h3 id="create-a-supervisord-file">Create a Supervisord File
&lt;/h3>&lt;p>By default, supervisord will &lt;a class="link" href="http://supervisord.org/configuration.html" target="_blank" rel="noopener"
>look in &lt;code>/etc/supervisor/conf.d/&lt;/code> for
configuration&lt;/a> on which programs to
run.&lt;/p>
&lt;p>We need to put a file in there that tells supervisord to run our &lt;code>run.sh&lt;/code>
script. Ansible has an integrated way of setting up templates which can be
placed on remote machines.&lt;/p>
&lt;p>I put a supervisord job template in the &lt;code>./templates&lt;/code> folder.&lt;/p>
&lt;pre>&lt;code>cat ./templates/run_process.j2
cat ./templates/run_process.j2
[program:{{ program_name }}]
command=sh run.sh
autostart=true
directory={{ project_location }}
stderr_logfile=/var/log/{{ program_name }}.err.log
stdout_logfile=/var/log/{{ program_name }}.out.log
&lt;/code>&lt;/pre>
&lt;p>This is a is normal INI-style config file, except it includes Jinja2
variables. We can use the Ansible &lt;a class="link" href="http://docs.ansible.com/ansible/template_module.html" target="_blank" rel="noopener"
>&lt;code>template&lt;/code>
module&lt;/a> to create a task
which fills in the variables with information about our program and copies it
into the &lt;code>conf.d&lt;/code> folder on the remote machine.&lt;/p>
&lt;p>The play for this would look like:&lt;/p>
&lt;pre>&lt;code>- hosts: digitalocean
vars:
project_location: /srv/long_running_python_process
program_name: long_running_process
supervisord_configs_path: /etc/supervisor/conf.d
tasks:
- name: Copy supervisord job file to remote
template:
src: ./templates/run_process.j2
dest: &amp;quot;{{ supervisord_configs_path }}/run_process.conf&amp;quot;
owner: root
&lt;/code>&lt;/pre>
&lt;h3 id="start-the-supevisord-job">Start the supevisord job
&lt;/h3>&lt;p>Finally, we just need to tell supervisord on our remote machine to start the
job described by &lt;code>run_process.conf&lt;/code>.&lt;/p>
&lt;p>Instead of issuing our own shell commands via Ansible, we can use the
&lt;a class="link" href="http://docs.ansible.com/ansible/supervisorctl_module.html" target="_blank" rel="noopener"
>&lt;code>supervisorctl&lt;/code>
module&lt;/a>. The task
is just:&lt;/p>
&lt;pre>&lt;code> - name: Start job
supervisorctl:
name: &amp;quot;{{ program_name }}&amp;quot;
state: present
&lt;/code>&lt;/pre>
&lt;p>&lt;code>state: present&lt;/code> ensures that Ansible calls &lt;code>supervisorctl reread&lt;/code> to load a
new config. Because our config has &lt;code>autostart=true&lt;/code>, supervisor will start it
as soon as the task is added.&lt;/p>
&lt;h2 id="the-big-playbook">The Big Playbook!
&lt;/h2>&lt;p>We can take everything we&amp;rsquo;ve described above and put it in one playbook.&lt;/p>
&lt;p>This playbook will:&lt;/p>
&lt;ul>
&lt;li>Install Miniconda using the role from Ansible Galaxy.&lt;/li>
&lt;li>Install and start Supervisor using the role we created.&lt;/li>
&lt;li>Clone the Github project we want to run.&lt;/li>
&lt;li>Create a Conda environment based on the environment.yml file.&lt;/li>
&lt;li>Create a supervisord file for running the program.&lt;/li>
&lt;li>Start the supervisord job.&lt;/li>
&lt;/ul>
&lt;p>All of this will be done on the host we specify (&lt;code>digitalocean&lt;/code>).&lt;/p>
&lt;pre>&lt;code>cat playbook.yml
cat playbook.yml
---
- hosts: digitalocean
vars:
project_repo: git://github.com/tdhopper/long_running_python_process.git
project_location: /srv/long_running_python_process
program_name: long_running_process
conda_folder_name: miniconda
conda_root: /root
supervisord_configs_path: /etc/supervisor/conf.d
roles:
- role: andrewrothstein.miniconda
miniconda_parent_dir: &amp;quot;{{ conda_root }}&amp;quot;
miniconda_name: &amp;quot;{{ conda_folder_name }}&amp;quot;
tags:
miniconda
- role: supervisor
tasks:
- name: Clone project code.
git:
repo: &amp;quot;{{ project_repo }}&amp;quot;
dest: &amp;quot;{{ project_location }}&amp;quot;
update: yes
tags:
git
- name: Create Conda environment from project environment file.
command: &amp;quot;{{conda_root}}/{{conda_folder_name}}/bin/conda env update&amp;quot;
args:
chdir: &amp;quot;{{ project_location }}&amp;quot;
tags:
conda
- name: Copy supervisord job file to remote
template:
src: ./templates/run_process.j2
dest: &amp;quot;{{ supervisord_configs_path }}/run_process.conf&amp;quot;
owner: root
tags:
conf
- name: Start job
supervisorctl:
name: &amp;quot;{{ program_name }}&amp;quot;
state: present
tags:
conf
&lt;/code>&lt;/pre>
&lt;p>To configure our machine, we just have to run &lt;code>ansible-playbook playbook.yml&lt;/code>.&lt;/p>
&lt;pre>&lt;code>ANSIBLE_NOCOWS=1 ansible-playbook playbook.yml
ANSIBLE_NOCOWS=1 ansible-playbook playbook.yml
PLAY [digitalocean] ************************************************************
TASK [setup] *******************************************************************
ok: [digitalocean]
TASK [andrewrothstein.unarchive-deps : resolve platform specific vars] *********
TASK [andrewrothstein.unarchive-deps : install common pkgs...] *****************
changed: [digitalocean] =&amp;gt; (item=[u'tar', u'unzip', u'gzip', u'bzip2'])
TASK [andrewrothstein.bash : install bash] *************************************
ok: [digitalocean]
TASK [andrewrothstein.alpine-glibc-shim : fix alpine] **************************
skipping: [digitalocean]
TASK [andrewrothstein.miniconda : download installer...] ***********************
changed: [digitalocean]
TASK [andrewrothstein.miniconda : installing....] ******************************
changed: [digitalocean]
TASK [andrewrothstein.miniconda : deleting installer...] ***********************
skipping: [digitalocean]
TASK [andrewrothstein.miniconda : link miniconda...] ***************************
changed: [digitalocean]
TASK [andrewrothstein.miniconda : conda updates] *******************************
changed: [digitalocean]
TASK [andrewrothstein.miniconda : make system default python etc...] ***********
skipping: [digitalocean] =&amp;gt; (item=etc/profile.d/miniconda.sh)
TASK [supervisor : Install supervisord] ****************************************
ok: [digitalocean]
TASK [supervisor : Start supervisord] ******************************************
ok: [digitalocean]
TASK [Clone project code.] *****************************************************
changed: [digitalocean]
TASK [Create Conda environment from project environment file.] *****************
changed: [digitalocean]
TASK [Copy supervisord job file to remote] *************************************
changed: [digitalocean]
TASK [Start job] ***************************************************************
changed: [digitalocean]
PLAY RECAP *********************************************************************
digitalocean : ok=13 changed=9 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;p>See that the &lt;code>PLAY RECAP&lt;/code> shows that everything was OK, no systems were
unreachable, and no tasks failed.&lt;/p>
&lt;p>We can verify that the program is running without error:&lt;/p>
&lt;pre>&lt;code>ssh digitalocean sudo supervisorctl status
ssh digitalocean sudo supervisorctl status
long_running_process RUNNING pid 4618, uptime 0:01:34
ssh digitalocean cat /var/log/long_running_process.out.log
ssh digitalocean cat /var/log/long_running_process.out.log
INFO:root:Process ran for the 1th time
INFO:root:Process ran for the 2th time
INFO:root:Process ran for the 3th time
INFO:root:Process ran for the 4th time
&lt;/code>&lt;/pre>
&lt;p>If your lucky (i.e. your systems and networks were setup sufficiently similar
to mine), you can run this exact same command to configure and start a process
on your own system. Moreover, you could use this exact same command to start
this program on an arbitrary number of machines by simply adding more hosts to
your inventory and play spec!&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>Ansible is a powerful, customizable tool. Unlike some similar tools, it
requires very little setup to start using it. As I&amp;rsquo;ve learned more about it,
I&amp;rsquo;ve seen more and more ways in which I could&amp;rsquo;ve used it in copious projects
in the past; I intend to make it a regular part of my toolkit. (Historically
I&amp;rsquo;ve done this kind of thing with hacky combinations of shell scripts and
&lt;a class="link" href="http://www.fabfile.org/" target="_blank" rel="noopener"
>Fabric&lt;/a>; Ansible would often be better.)&lt;/p>
&lt;p>This tutorial just scratches the surface of the Ansible functionality. If you
want to learn more, I again recommend reading through the
&lt;a class="link" href="http://docs.ansible.com/ansible/index.html" target="_blank" rel="noopener"
>docs&lt;/a>; they&amp;rsquo;re very good. Of
course, you should start writing and running your own playbooks as soon as
possible! I also liked &lt;a class="link" href="https://serversforhackers.com/an-ansible-tutorial" target="_blank" rel="noopener"
>this tutorial from Server Admin for
Programmers&lt;/a>. If you want
to compare Ansible to alternatives, the &lt;a class="link" href="https://valdhaus.co/books/taste-test-puppet-chef-salt-stack-ansible.html" target="_blank" rel="noopener"
>Taste Test book&lt;/a> by Matt Jaynes looks promising. For more on Supervisor,
&lt;a class="link" href="https://serversforhackers.com/monitoring-processes-with-supervisord" target="_blank" rel="noopener"
>serversforhackers.com&lt;/a> has a nice tutorial, and &lt;a class="link" href="http://supervisord.org/" target="_blank" rel="noopener"
>its docs are
thorough&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>I wrote a tutorial on using &lt;a class="link" href="https://twitter.com/ansible" target="_blank" rel="noopener"
>@ansible&lt;/a> and
supervisor to deploy a long running Python process to a
&lt;a class="link" href="https://twitter.com/digitalocean" target="_blank" rel="noopener"
>@digitalocean&lt;/a>
VPS.&lt;a class="link" href="https://t.co/uPC8bY5haD" target="_blank" rel="noopener"
>https://t.co/uPC8bY5haD&lt;/a>&lt;/p>
&lt;p>— Tim Hopper 🔭 (@tdhopper) &lt;a class="link" href="https://twitter.com/tdhopper/status/845256769429483520" target="_blank" rel="noopener"
>March 24,
2017&lt;/a>&lt;/p>
&lt;/blockquote></description></item><item><title>Data Scientists Need More Automation</title><link>https://tdhopper.com/blog/data-scientists-need-more-automation/</link><pubDate>Thu, 17 Nov 2016 02:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/data-scientists-need-more-automation/</guid><description>&lt;p>Many data scientists aren&amp;rsquo;t lazy enough.&lt;/p>
&lt;p>Whether we are managing production services or running computations on AWS
machines, many data scientists are working on computers besides their laptops.&lt;/p>
&lt;p>For me, this often takes the form of SSH-ing into remote boxes, manually
configuring the system with a combination of apt installs, &lt;a class="link" href="http://conda.pydata.org/docs/using/envs.html" title="Managing
environments — Conda documentation"
target="_blank" rel="noopener"
>Conda
environments&lt;/a>, and bash scripts.&lt;/p>
&lt;p>To run my service or scripts, I open a &lt;a class="link" href="https://tmux.github.io/" title="tmux"
target="_blank" rel="noopener"
>tmux&lt;/a>
window, activate my virtual environement, and start the process. (When I have
to do this on multiple machines, I&amp;rsquo;m occasionally clever enough to use tmux to
broadcast the commands to multiple terminal windows.)&lt;/p>
&lt;p>When I need to check my logs or see the output, I SSH back into each box,
reconnect to tmux (after I remember the name of my session), and tail my logs.
When running on multiple boxes, I repeat this process N times. If I need to
restart a process, I flip through my tmux tabs until I find the correct
process, kill it with a Ctrl-C, and use the up arrow to reload the last run
command.&lt;/p>
&lt;p>All of this works, of course. &lt;a class="link" href="https://xkcd.com/1319/" target="_blank" rel="noopener"
>And as we all know&lt;/a>, &lt;a class="link" href="http://xkcd.com/974/" target="_blank" rel="noopener"
>a
simple solution that works&lt;/a> &lt;a class="link" href="https://xkcd.com/1445/" target="_blank" rel="noopener"
>can be
preferable&lt;/a> to a fragile solution that requires
constant maintenance. That said, I suspect many of us aren&amp;rsquo;t lazy enough. We
don&amp;rsquo;t spend enough time automating tasks and processes. Even when we don&amp;rsquo;t
save time by doing it, we may save &lt;a class="link" href="http://www.johndcook.com/blog/2015/12/22/automate-to-save-mental-energy-not-time/" target="_blank" rel="noopener"
>mental overhead&lt;/a>.&lt;/p>
&lt;p>I recently introduced several colleagues to some Python-based tools that can
help. &lt;a class="link" href="http://www.fabfile.org/" target="_blank" rel="noopener"
>Fabric&lt;/a> is a &amp;ldquo;library and command-line tool
for streamlining the use of SSH for application deployment or systems
administration tasks.&amp;rdquo; Fabric allows you to encapsulate sequences of commands
as you might with a Makefile. It&amp;rsquo;s killer feature is the ease with which it
lets you execute those commands on remote machines over SSH. With Fabric, you
could tail all the logs on all your nodes with a single command executed in
your local terminal. There are &lt;a class="link" href="https://www.youtube.com/results?search_query=python&amp;#43;fabric" target="_blank" rel="noopener"
>a number of talks about Fabric on
Youtube&lt;/a> if you
want to learn more. One of my colleagues reduced his daily workload by writing
his system management tasks into a Fabric file.&lt;/p>
&lt;p>Another great tool is &lt;a class="link" href="http://supervisord.org/" target="_blank" rel="noopener"
>Supervisor&lt;/a>. If you run long
running processes in tmux/screen/nohup, Supervisor might be for you. It allows
you to define the tasks you want to run in an INI file and &amp;ldquo;provides you with
one place to start, stop, and monitor your processes&amp;rdquo;. Supervisor will log the
stdout and stderr to a log location of your choice. It can be a little
confusing to set up, but will likely make your life easier in the longer run.&lt;/p>
&lt;p>A tool I want to learn but haven&amp;rsquo;t is &lt;a class="link" href="https://www.ansible.com/" target="_blank" rel="noopener"
>Ansible&lt;/a>, &amp;ldquo;a
free-software platform for configuring and managing computers which combines
multi-node software deployment, ad hoc task execution, and configuration
management&amp;rdquo;. Unlike Chef and Puppet, Ansible doesn&amp;rsquo;t require an agent on the
systems you need to configure; it does all the configuration over SSH. You can
use Ansible to configure your systems and install your dependencies, even
&lt;a class="link" href="https://github.com/zenoamaro/ansible-supervisord" target="_blank" rel="noopener"
>Supervisor&lt;/a>! Ansible is
written in Python and, mercifully, doesn&amp;rsquo;t require learning a Ruby-based DSL
(as does Chef).&lt;/p>
&lt;p>Recently I&amp;rsquo;ve been thinking that Fabric, Supervisor, and Ansible combined
become a powerful toolset for management and configuration of data science
systems. Each tool is also open source and can be installed in a few minutes.
Each tool is well documented and offers helpful tutorials on getting started;
however, learning to use them effectively may require some effort.&lt;/p>
&lt;p>I would love to see someone create training materials on these tools (and
others!) focused on how data scientists can take improve their system
management, configuration, and operations. A screencast series may be the
perfect thing. Someone please help data scientists be lazier, do less work,
and reduce the mental overhead of dealing with computers!&lt;/p></description></item><item><title>Filter by date in a Pandas MultiIndex</title><link>https://tdhopper.com/blog/filter-by-date-in-a-pandas-multiindex/</link><pubDate>Tue, 08 Nov 2016 22:17:00 +0000</pubDate><guid>https://tdhopper.com/blog/filter-by-date-in-a-pandas-multiindex/</guid><description>&lt;p>I always forget how to do this.&lt;/p>
&lt;p>The pandas &lt;code>DataFrame.loc&lt;/code> method allows for &lt;em>label&lt;/em> -based filtering of data
frames. The &lt;a class="link" href="http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced-indexing-with-hierarchical-index" target="_blank" rel="noopener"
>Pandas docs&lt;/a> show how
it can be used to filter a &lt;code>MultiIndex&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">In [39]: df
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Out[39]:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> A B C
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">first second
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bar one 0.895717 0.410835 -1.413681
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> two 0.805244 0.813850 1.607920
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">baz one -1.206412 0.132003 1.024180
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> two 2.565646 -0.827317 0.569605
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foo one 1.431256 -0.076467 0.875906
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> two 1.340309 -1.187678 -2.211372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">qux one -1.170299 1.130127 0.974466
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> two -0.226169 -1.436737 -2.006747
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">In [40]: df.loc[&amp;#39;bar&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Out[40]:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> A B C
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">second
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">one 0.895717 0.410835 -1.413681
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">two 0.805244 0.813850 1.607920
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">In [41]: df.loc[&amp;#39;bar&amp;#39;, &amp;#39;two&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Out[41]:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">A 0.805244
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">B 0.813850
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">C 1.607920
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Name: (bar, two), dtype: float64
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It turns out you can easily use it to filter a &lt;code>DateTimeIndex&lt;/code> level by a
single date with &lt;code>df['2016-11-07']&lt;/code> or a range of dates with
&lt;code>df['2016-11-07:2016-11-11']&lt;/code>. This applies whether or not its a &lt;code>MultiIndex&lt;/code>.&lt;/p>
&lt;p>If you get an error like &lt;code>KeyError: 'Key length (1) was greater than MultiIndex lexsort depth (0)'&lt;/code>, it&amp;rsquo;s because &amp;ldquo;MultiIndex Slicing requires the
index to be fully lexsorted&amp;rdquo;. You may fix your problem by calling &lt;code>df = df.sort_index()&lt;/code>.&lt;/p></description></item><item><title>Speeding up PyMC3 NUTS Sampler</title><link>https://tdhopper.com/blog/speeding-up-pymc3-nuts-sampler/</link><pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/speeding-up-pymc3-nuts-sampler/</guid><description>&lt;img src="https://tdhopper.com/images/til.png" alt="Featured image of post Speeding up PyMC3 NUTS Sampler" />&lt;p>I&amp;rsquo;m trying to use the &lt;a class="link" href="https://pymc-devs.github.io/pymc3/api.html?highlight=nuts#module-pymc3.step_methods.nuts" target="_blank" rel="noopener"
>NUTS sampler&lt;/a> in &lt;a class="link" href="https://github.com/pymc-devs/pymc3" title="GitHub - pymc-devs/pymc3: Probabilistic Programming in Python. Uses Theano as a backend, supports NUTS and ADVI."
target="_blank" rel="noopener"
>PyMC3&lt;/a>&lt;/p>
&lt;p>However, it was running at 2 iterations per second on my model, while the Metropolis Hastings sampler ran 450x faster.&lt;/p>
&lt;p>I showed my example to some of the PyMC3 devs on Twitter, and &lt;a class="link" href="https://de.linkedin.com/in/thomas-wiecki-46339244" title="Thomas Wiecki"
target="_blank" rel="noopener"
>Thomas Wiecki&lt;/a> showed me this trick:&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">&lt;a href="https://twitter.com/tdhopper">@tdhopper&lt;/a> &lt;a href="https://twitter.com/Springcoil">@Springcoil&lt;/a> You need pm.NUTS(scaling=np.power(model.dict_to_array(v_params.stds), 2), is_cov=True) (terrible syntax, I know).&lt;/p>&amp;mdash; Thomas Wiecki (@twiecki) &lt;a href="https://twitter.com/twiecki/status/796007019941462016">November 8, 2016&lt;/a>&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>It resulted in a 25x speedup of the NUTS sampler. The code looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">pm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Model&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># SETUP MODEL HERE&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sds&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">elbo&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">variational&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">advi&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">200000&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">step&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">NUTS&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaling&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">power&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dict_to_array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sds&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">pm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sample&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">niter&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">is_cov&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">start&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">mu&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Understanding Probabilistic Topic Models By Simulation</title><link>https://tdhopper.com/blog/understanding-probabilistic-topic-models-by-simulation/</link><pubDate>Tue, 25 Oct 2016 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/understanding-probabilistic-topic-models-by-simulation/</guid><description>&lt;p>I gave a talk last week at Research Triangle Analysts on understanding probabilistic topic models (specificly LDA) by using Python for simulation. Here&amp;rsquo;s the description:&lt;/p>
&lt;blockquote>
&lt;p>Latent Dirichlet Allocation and related topic models are often presented in the form of complicated equations and confusing diagrams. Tim Hopper presents LDA as a generative model through probabilistic simulation in simple Python. Simulation will help data scientists to understand the model assumptions and limitations and more effectively use black box LDA implementations.&lt;/p>
&lt;/blockquote>
&lt;p>You can watch the video on &lt;a class="link" href="https://www.youtube.com/watch?v=Wy-XhT2sHgM&amp;amp;feature=youtu.be" target="_blank" rel="noopener"
>Youtube&lt;/a>:&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/Wy-XhT2sHgM"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>I gave a &lt;a class="link" href="https://www.youtube.com/watch?v=_R66X_udxZQ" target="_blank" rel="noopener"
>shorter version of the talk at PyData NYC 2015&lt;/a>.&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/_R66X_udxZQ"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div></description></item><item><title>Testing whether a Python string contains an integer</title><link>https://tdhopper.com/blog/testing-whether-a-python-string-contains-an-integer/</link><pubDate>Fri, 29 Apr 2016 15:13:00 +0000</pubDate><guid>https://tdhopper.com/blog/testing-whether-a-python-string-contains-an-integer/</guid><description>&lt;p>If you want to check whether a Python string is an integer, you can try
casting to an int with &lt;code>int()&lt;/code> and catching the &lt;code>ValueError&lt;/code> if it&amp;rsquo;s not an
integer:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">is_integer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">base&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">base&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">base&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To check for &lt;em>nonnegative&lt;/em> integers, you can use the &lt;a class="link" href="https://docs.python.org/3.8/library/stdtypes.html#str.isdigit" target="_blank" rel="noopener"
>&lt;code>str.is_digit()&lt;/code>
method&lt;/a>. It
will &amp;ldquo;return true if all characters in the string are digits and there is at
least one character, false otherwise:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="s2">&amp;#34;123&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">isdigit&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="s2">&amp;#34;-123&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">isdigit&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Thanks to &lt;a class="link" href="https://twitter.com/trochee/status/726162607460114433" target="_blank" rel="noopener"
>Jeremy Kahn for reminding
me&lt;/a> that &lt;code>isdigit&lt;/code> only
detects positive integers.&lt;/p></description></item><item><title>Don't Buffer Python's stdout</title><link>https://tdhopper.com/blog/dont-buffer-pythons-stdout/</link><pubDate>Tue, 26 Apr 2016 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/dont-buffer-pythons-stdout/</guid><description>&lt;img src="https://tdhopper.com/images/til.png" alt="Featured image of post Don't Buffer Python's stdout" />&lt;p>I was using &lt;code>[tee](http://man7.org/linux/man-pages/man1/tee.1.html)&lt;/code> with a long running Python process, but I wasn&amp;rsquo;t seeing any output. This is a result of Python buffering the stdout stream. You can run force Python to run in &lt;a class="link" href="https://docs.python.org/2/using/cmdline.html#cmdoption-u" target="_blank" rel="noopener"
>unbuffered mode&lt;/a> using the &lt;code>-u&lt;/code> flag at the command line.&lt;/p>
&lt;blockquote>
&lt;p>Force stdin, stdout and stderr to be totally unbuffered. On systems where it matters, also put stdin, stdout and stderr in binary mode.&lt;/p>
&lt;/blockquote></description></item><item><title>Column binding two Panda's Dataframes</title><link>https://tdhopper.com/blog/column-binding-two-pandas-dataframes/</link><pubDate>Mon, 11 Apr 2016 20:56:00 +0000</pubDate><guid>https://tdhopper.com/blog/column-binding-two-pandas-dataframes/</guid><description>&lt;p>Joining two Pandas DataFrames with an equal number of rows is slightly harder
than it appears. In R, you just use the &lt;code>cbind&lt;/code> function.&lt;/p>
&lt;p>As &lt;a class="link" href="http://stackoverflow.com/questions/33088010/pandas-column-bind-cbind-two-data-frames" target="_blank" rel="noopener"
>this&lt;/a> StackOverflow question shows, in Pandas it&amp;rsquo;s easy to
end up with something like this:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">unique_id lacet_number latitude longitude
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">0 NaN NaN -93.193560 31.217029
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 NaN NaN -93.948082 35.360874
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2 NaN NaN -103.131508 37.787609
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">15 5570613 TLA-0138365 NaN NaN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">24 5025490 EMP-0138757 NaN NaN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">36 4354431 DXN-0025343 NaN NaN
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This results from the indices not being identical. Frustratingly (to me) the
&lt;code>ignore_index&lt;/code> argument doesn&amp;rsquo;t give the 3-rowed DataFrame I&amp;rsquo;d hope it gives.&lt;/p>
&lt;p>As the &lt;a class="link" href="http://stackoverflow.com/a/33088410/982745" target="_blank" rel="noopener"
>accepted answer&lt;/a> on that
question shows, the thing to do is reset the indices on the DataFrames before
concatenating:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">pd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">concat&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">df_a&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reset_index&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">drop&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">df_b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reset_index&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">drop&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)],&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Printing Pandas Data Frames as HTML in Jupyter Notebooks</title><link>https://tdhopper.com/blog/printing-pandas-data-frames-as-html-in-jupyter-notebooks/</link><pubDate>Wed, 23 Mar 2016 14:18:00 +0000</pubDate><guid>https://tdhopper.com/blog/printing-pandas-data-frames-as-html-in-jupyter-notebooks/</guid><description>&lt;img src="https://tdhopper.com/panda.png" alt="Featured image of post Printing Pandas Data Frames as HTML in Jupyter Notebooks" />&lt;p>Jupyter notebooks nicely render Pandas data frames if they&amp;rsquo;re the last line in
a cell. It renders the HTML version of the data frame returned by
&lt;code>pandas.DataFrame.to_html()&lt;/code>. However, if you call &lt;code>print(df)&lt;/code> in a cell, the
data frame is rendered in less readable text-based output.&lt;/p>
&lt;p>Despite using Notebooks regularly for years, I&amp;rsquo;d never bothered to figure out
a way around this. However, the solution is easy.&lt;/p>
&lt;p>Instead of &lt;code>print(df)&lt;/code> you use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">IPython.display&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">display&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">display&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Creating Impala Tables from Pandas Dataframes</title><link>https://tdhopper.com/blog/creating-impala-tables-from-pandas-dataframes/</link><pubDate>Tue, 15 Mar 2016 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/creating-impala-tables-from-pandas-dataframes/</guid><description>&lt;img src="https://tdhopper.com/images/til.png" alt="Featured image of post Creating Impala Tables from Pandas Dataframes" />&lt;p>&lt;a class="link" href="http://wesmckinney.com/" title="Wes McKinney"
target="_blank" rel="noopener"
>Wes Mckinney&lt;/a>&amp;rsquo;s &lt;a class="link" href="http://docs.ibis-project.org/index.html" target="_blank" rel="noopener"
>Ibis&lt;/a>, a Pythonic interface to Impala, has functionality for creating &lt;a class="link" href="https://www.cloudera.com/products/apache-hadoop/impala.html" title="Apache Impala"
target="_blank" rel="noopener"
>Impala&lt;/a> tables from &lt;a class="link" href="http://pandas.pydata.org/" title="Python Data Analysis Library &amp;amp;mdash; pandas: Python Data Analysis Library"
target="_blank" rel="noopener"
>Python Pandas&lt;/a> dataframes.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">pandas&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">pd&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">ibis&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ibis&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">hdfs_connect&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">host&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">webhdfs_host&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">port&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">webhdfs_port&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">client&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ibis&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">impala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">connect&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">host&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">impala_host&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">port&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">impala_port&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hdfs_client&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">hdfs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">database&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;ibis_testing&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DataFrame&lt;/span>&lt;span class="p">({&lt;/span>&lt;span class="s1">&amp;#39;foo&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="s1">&amp;#39;bar&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;a&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;b&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;c&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;d&amp;#39;&lt;/span>&lt;span class="p">]})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">db&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">create_table&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;pandas_table&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="http://docs.ibis-project.org/impala.html#creating-tables" target="_blank" rel="noopener"
>This functionality&lt;/a>, added in Ibis 0.6.0, is &lt;em>much&lt;/em> easier that manually move data to HDFS and loading into Impala.&lt;/p></description></item><item><title>My Python Environment Workflow with Conda</title><link>https://tdhopper.com/blog/my-python-environment-workflow-with-conda/</link><pubDate>Tue, 24 Nov 2015 14:41:00 +0000</pubDate><guid>https://tdhopper.com/blog/my-python-environment-workflow-with-conda/</guid><description>&lt;img src="https://tdhopper.com/conda.png" alt="Featured image of post My Python Environment Workflow with Conda" />&lt;p>Many new Python programmers rely on their system install of Python to run
their scripts. There are several good reasons to stop using the system Python.
First, it&amp;rsquo;s probably an old version of Python. Secondly, if you install 3rd
party packages with &lt;a class="link" href="https://pypi.python.org/pypi/pip" target="_blank" rel="noopener"
>pip&lt;/a>, every package is
installed into the same globally accessible directory. While this may sound
convenient, it causes problems if you (1) install different packages with the
same name (2) need to use different versions of the same package (3) upgrade
your operating system (OS X will delete all the packages you have installed).&lt;/p>
&lt;p>For many years, best practice for Python developers was to use virtualenv to
create a sandbox-ed environment for each project. If you use virtualenv, each
project you work on can have its own version of Python with its own 3rd party
packages (hopefully specified in an &lt;code>requirements.txt&lt;/code> file). In my
experience, getting started with virtualenv is cumbersome and confusing; to
this day, I have to look up the command to create a Python 3 virtualenv.
virtualenv also provides no helping in actually managing Python versions. You
have to install each version yourself and then tell virtualenv to use it.&lt;/p>
&lt;p>In 2015, I have almost exclusively used Python installations provided through
&lt;a class="link" href="https://www.continuum.io/" title="Continuum"
target="_blank" rel="noopener"
>Continuum Analytics&amp;rsquo;s&lt;/a>
&lt;a class="link" href="http://conda.pydata.org/docs/intro.html" title="Intro to conda —
Conda documentation"
target="_blank" rel="noopener"
>Conda/Anaconda&lt;/a> platform. I have also switched from using virtualenvs
to using &lt;a class="link" href="http://conda.pydata.org/docs/using/envs.html" title="Managing environments — Conda documentation"
target="_blank" rel="noopener"
>conda environments&lt;/a>, and I am loving it.&lt;/p>
&lt;p>Before explaining my workflow, here&amp;rsquo;s a quick glossary of the similarly-named
products that Continuum offers.&lt;/p>
&lt;ol>
&lt;li>&lt;a class="link" href="http://conda.pydata.org/docs/intro.html" target="_blank" rel="noopener"
>conda&lt;/a>: &amp;ldquo;Conda is an open source package management system and environment management system for installing multiple versions of software packages and their dependencies and switching easily between them. It works on Linux, OS X and Windows, and was &lt;em>created for Python programs but can package and distribute any software.&lt;/em> &amp;quot; A conda install provides a whole suite of command line tools for installing and managing packages and environments. Because conda works for any software, it can even install different versions of Python (unlike pip).&lt;/li>
&lt;li>&lt;a class="link" href="https://www.continuum.io/downloads" target="_blank" rel="noopener"
>Anaconda&lt;/a>: &amp;ldquo;Anaconda is a completely free Python distribution (including for commercial use and redistribution). It includes more than 300 of the most popular Python packages for science, math, engineering, and data analysis.&amp;rdquo; It is available across platforms and installable through a binary.&lt;/li>
&lt;li>&lt;a class="link" href="https://anaconda.org" target="_blank" rel="noopener"
>Anaconda Cloud&lt;/a>: Also known as Anaconda.org and formerly known as Binstar, &amp;ldquo;Anaconda Cloud is a package management service where you can host software packages of all kinds.&amp;rdquo; Anaconda Cloud is a package repository analogous to PyPI. Packages are installed via the conda command line tool instead of Pip. By default, the &lt;code>conda install&lt;/code> command installs packages from a curated collection of packages (a superset of those in Anaconda). Continuum allows users to host their own packages on Anaconda Cloud; these packages can also be installed through &lt;code>conda install&lt;/code> using the &lt;code>-n&lt;/code> flag with the username.&lt;/li>
&lt;/ol>
&lt;p>Conda, Anaconda, and Anaconda cloud are distinct but interrelated tools;
keeping them straight can be hard, but is helpful.&lt;/p>
&lt;p>Conda (the package manager) can be installed in two ways. Through the
&lt;a class="link" href="http://conda.pydata.org/miniconda.html" target="_blank" rel="noopener"
>Miniconda&lt;/a> installer or the
&lt;a class="link" href="https://www.continuum.io/downloads" target="_blank" rel="noopener"
>Anaconda&lt;/a> installer. Both install the
package manager, but the latter also installs the 300+ packages for scientific
Python. (Installing Anaconda is equivalent to installing Miniconda and then
running &lt;code>conda install anaconda&lt;/code>.)&lt;/p>
&lt;h2 id="conda-environment-files">Conda Environment Files
&lt;/h2>&lt;p>It has become standard for pip users to create a &lt;code>requirements.txt&lt;/code> file for
specifying dependencies for a particular project. Often, a developer working a
project will (1) create and activate a virtual environment (2) run &lt;code>pip install -r requirements.txt&lt;/code> to build an isolated development environment with
the needed packages.&lt;/p>
&lt;p>Conda provides an analogous (but more powerful) file: &lt;code>environment.yml&lt;/code>.&lt;/p>
&lt;p>A simple &lt;code>environment.yml&lt;/code> file might look like this:&lt;/p>
&lt;pre>&lt;code>name: numpy-env
dependencies:
- python=3
- numpy
&lt;/code>&lt;/pre>
&lt;p>If you are in a directory containing this file, you can run &lt;code>$ conda env create&lt;/code> to create a Conda environment named &lt;code>numpy-env&lt;/code> that runs Python 3 and
has &lt;a class="link" href="http://www.numpy.org/" title="NumPy — Numpy"
target="_blank" rel="noopener"
>numpy&lt;/a> installed[^numpy]. Run &lt;code>$ source activate numpy-env&lt;/code> to activate this environment. Once activated,
running &lt;code>$ python&lt;/code> will run Python 3 from your environment instead of the
globally installed Python for your system. Moreover, you will be able to
&lt;code>import numpy&lt;/code> but not any of the 3rd party packages installed globally.&lt;/p>
&lt;p>&lt;code>environment.yml&lt;/code> can also install packages via pip with this syntax:&lt;/p>
&lt;pre>&lt;code>name: pip-env
dependencies:
- python
- pip
- pip:
- pypi-package-name
&lt;/code>&lt;/pre>
&lt;p>I see &lt;code>environment.yml&lt;/code> files as a positive development from
&lt;code>requirements.txt&lt;/code> files for several reasons. Foremost, they allow you to
specify the version of Python you want to use. At Pydata NYC 2015, many
presenters provided their code in Github repositories without specifying
anywhere whether they were using Python 2 or 3. Because I &lt;a class="link" href="https://github.com/tdhopper/pydata-nyc-2015/blob/55b9d2892b18e1d191325fc1890740901723dcfd/environment.yml" target="_blank" rel="noopener"
>included a YAML file&lt;/a>,
attendees could see exactly what version I was using and quickly install it
with &lt;code>conda env create&lt;/code>. I also like being able to specify the name of the
environment in the file; this is particularly helpful when working with
others. Finally, because conda can install from PyPI via pip,
&lt;code>environment.yml&lt;/code> files provide no less functionality than a
&lt;code>requirements.txt&lt;/code> file provides.&lt;/p>
&lt;h2 id="my-python-environment-workflow">My Python Environment Workflow
&lt;/h2>&lt;p>Lately, whenever I am working on a new project (however big or small), I
follow the following steps:&lt;/p>
&lt;ol>
&lt;li>Create a project folder in the &lt;code>~/repos/&lt;/code> directory on my computer.&lt;/li>
&lt;li>Create an &lt;code>environment.yml&lt;/code> file in the directory. Typically the environment name will be the same as the folder name. At minimum, it will specify the version of Python I want to use; it will often include &lt;code>anaconda&lt;/code> as a dependency.&lt;/li>
&lt;li>Create the conda environment with &lt;code>$ conda env create&lt;/code>.&lt;/li>
&lt;li>Activate the conda environment with &lt;code>$ source activate ENV_NAME&lt;/code>.&lt;/li>
&lt;li>Create a &lt;code>.env&lt;/code> file containing the line &lt;code>source activate ENV_NAME&lt;/code>. Because I have &lt;a class="link" href="https://github.com/kennethreitz/autoenv" target="_blank" rel="noopener"
>autoenv&lt;/a> installed, this file will be run every time I navigate to the project folder in the Terminal. Therefore, my conda environment will be activated as soon as I navigate to the folder.&lt;/li>
&lt;li>Run &lt;code>$ git init&lt;/code> to make the folder a Git repository. I then run &lt;code>$ git add environment.yml &amp;amp;&amp;amp; git commit -m 'initial commit'&lt;/code> to add the YAML file to the repository.&lt;/li>
&lt;li>If I want to push the repository to Github, I use &lt;code>$ git create&lt;/code> using Github&amp;rsquo;s &lt;a class="link" href="https://github.com/github/hub" target="_blank" rel="noopener"
>hub&lt;/a> commands. I then push the master branch with &lt;code>$ git push -u origin master&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>As I add dependencies to my project, I try to be sure I add them to my
&lt;code>environment.yml&lt;/code> file.&lt;/p>
&lt;p>A major benefit of all this is how easily reproducible a development
environment becomes. If a colleague or conference attendee wants to run my
code, they can setup the dependencies ( &lt;em>including&lt;/em> Python version) by (1)
cloning the repository, (2) running &lt;code>$ conda env create&lt;/code>, (3) running &lt;code>$ source activate ENV_NAME&lt;/code>. It&amp;rsquo;s easy enough for me to drop those instructions
and further instructions for running the code in a README file. If I&amp;rsquo;m feeling
especially helpful, I&amp;rsquo;ll create a
&lt;a class="link" href="http://mrbook.org/blog/tutorials/make/" title="Makefiles – Mrbook&amp;#39;s
Stuff"
target="_blank" rel="noopener"
>Makefile&lt;/a> or &lt;a class="link" href="http://www.fabfile.org/" title="Welcome to Fabric! — Fabric
documentation"
target="_blank" rel="noopener"
>Fabfile&lt;/a> to encapsulate commands for core functionality of the code.&lt;/p>
&lt;p>An even larger benefit is that I can return to a project after, days, months,
or years and quickly start developing without first having to hunt for &lt;code>print&lt;/code>
statements to figure out whether I was using Python 2 or 3.&lt;/p>
&lt;p>I&amp;rsquo;ve come to love &lt;code>environment.yml&lt;/code> files, and I think you might too.&lt;/p></description></item><item><title>Nonparametric Latent Dirichlet Allocation</title><link>https://tdhopper.com/blog/wrapping-up-on-nonparametric-bayes/</link><pubDate>Fri, 16 Oct 2015 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/wrapping-up-on-nonparametric-bayes/</guid><description>&lt;p>Today is my last day at &lt;a class="link" href="http://qadium.com" target="_blank" rel="noopener"
>Qadium&lt;/a>. Next week, I am joining the data science team at &lt;a class="link" href="http://distilnetworks.com" target="_blank" rel="noopener"
>Distil Networks&lt;/a>.&lt;/p>
&lt;p>I&amp;rsquo;ve been privileged to work with &lt;a class="link" href="http://ericjonas.com/" target="_blank" rel="noopener"
>Eric Jonas&lt;/a> on the &lt;a class="link" href="http://datamicroscopes.github.io" target="_blank" rel="noopener"
>data microscopes&lt;/a> project for the past 8 months. In particular, I contributed the implementation of &lt;a class="link" href="https://github.com/datamicroscopes/lda" target="_blank" rel="noopener"
>Nonparametric Latent Dirichlet Allocation&lt;/a>.&lt;/p>
&lt;p>I published a collection of notes on nonparametric Bayesian methods and Latent Dirichlet Allocation at &lt;a class="link" href="https://dp.tdhopper.com" target="_blank" rel="noopener"
>dp.tdhopper.com&lt;/a>. I hope this will be useful to other students and researchers of these methods.&lt;/p></description></item><item><title>Notes on Dirichlet Processes</title><link>https://tdhopper.com/blog/wrapping-up-on-nonparametric-bayes/</link><pubDate>Fri, 16 Oct 2015 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/wrapping-up-on-nonparametric-bayes/</guid><description>&lt;p>I have published some &lt;a class="link" href="https://dp.tdhopper.com" target="_blank" rel="noopener"
>notes on the Dirichlet distribute, Dirichlet processes, Gibbs sampling for mixture models and nonparametric mixture models, and the Gibbs sampler for nonparametric Latent Dirichlet Allocation&lt;/a>.&lt;/p>
&lt;p>This is related to my work on a Python implementation of &lt;a class="link" href="https://github.com/datamicroscopes/lda" target="_blank" rel="noopener"
>Hierarchical Dirichlet Process Latent Dirichlet Allocation&lt;/a>.&lt;/p></description></item><item><title>Handy One-off Webpages</title><link>https://tdhopper.com/blog/handy-one-off-webpages/</link><pubDate>Mon, 27 Jul 2015 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/handy-one-off-webpages/</guid><description>&lt;p>I&amp;rsquo;m starting to love single-page informational websites. For example:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="http://keepachangelog.com" target="_blank" rel="noopener"
>Keep a CHANGELOG&lt;/a>: &lt;a class="link" href="http://olivierlacan.com/" title="Olivier Lacan"
target="_blank" rel="noopener"
>Olivier Lacan&lt;/a>&amp;rsquo;s guide to writing a &lt;em>CHANGELOG.md&lt;/em> for open source projects.&lt;/li>
&lt;li>&lt;a class="link" href="http://strftime.org" target="_blank" rel="noopener"
>strftime&lt;/a>: &lt;a class="link" href="https://twitter.com/mccutchen" title="Will McCutchen (@mccutchen) | Twitter"
target="_blank" rel="noopener"
>Will McCutchen&lt;/a>&amp;rsquo;s little page of the easily forgettable date formatting codes for Python programmers.&lt;/li>
&lt;li>&lt;a class="link" href="http://pyformat.info" target="_blank" rel="noopener"
>PyFormat&lt;/a>: &lt;a class="link" href="https://twitter.com/ulope" title="Ulrich Petri (@ulope) | Twitter"
target="_blank" rel="noopener"
>Ulrich Petri&lt;/a> and &lt;a class="link" href="https://github.com/zerok" title="zerok (Horst Gutmann) Âˇ GitHub"
target="_blank" rel="noopener"
>Horst Gutmann&lt;/a>&amp;rsquo;s guide to new style (&lt;code>.format()&lt;/code>) string formatting in Python.&lt;/li>
&lt;li>&lt;a class="link" href="https://twofactorauth.org" target="_blank" rel="noopener"
>Two Factor Auth&lt;/a>: &amp;ldquo;List of websites and whether or not they support 2FA.&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>My website &lt;a class="link" href="http://shouldigetaphd.com" target="_blank" rel="noopener"
>Should I Get a Phd?&lt;/a> is in this same vein.&lt;/p>
&lt;p>Publishing a site like this is very cheap with &lt;a class="link" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html" target="_blank" rel="noopener"
>static hosting on AWS&lt;/a>. I would love to see more of them created!&lt;/p></description></item><item><title>Introduction to PySpark</title><link>https://tdhopper.com/blog/intro-to-pyspark/</link><pubDate>Sat, 28 Feb 2015 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/intro-to-pyspark/</guid><description>&lt;p>I gave a talk at the Research Triangle Analysts meetup about Pyspark. It wasn&amp;rsquo;t recorded, but you can &lt;a class="link" href="http://nbviewer.jupyter.org/format/slides/github/tdhopper/rta-pyspark-presentation/blob/master/slides.ipynb#/" target="_blank" rel="noopener"
>see the IPython notebook I presented from&lt;/a>.&lt;/p></description></item><item><title>Tracking Weight Loss with R, Hazel, Withings, and IFTTT</title><link>https://tdhopper.com/blog/tracking-weight-loss-with-r-hazel-withings-and-ifttt/</link><pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/tracking-weight-loss-with-r-hazel-withings-and-ifttt/</guid><description>&lt;p>As I have &lt;a class="link" href="https://tdhopper.com/blog/2013/Jul/26/noisy-series-and-body-weight/" >noted&lt;/a> &lt;a class="link" href="https://tdhopper.com/blog/2013/Nov/28/noisy-series-and-body-weight-take-2/" >before&lt;/a>, body weight is a noisy thing. Day to day, your weight will probably fluctuate by several pounds. If you&amp;rsquo;re trying to lose weight, this noise can cause unfounded frustration and premature excitement.&lt;/p>
&lt;p>When I started a serious weight loss plan a year and a half ago, I bought a wifi-enabled &lt;a class="link" href="http://www.withings.com" target="_blank" rel="noopener"
>Withings Scale&lt;/a>. The scale allows me to automatically sync my weight with &lt;a class="link" href="http://www.bustan.net/" target="_blank" rel="noopener"
>Montior Your Weight&lt;/a>, &lt;a class="link" href="http://www.myfitnesspal.com" target="_blank" rel="noopener"
>MyFitnessPal&lt;/a>, &lt;a class="link" href="http://runkeeper.com/home" title="RunKeeper"
target="_blank" rel="noopener"
>RunKeeper&lt;/a>, and other fitness apps on my phone. IFTTT also has &lt;a class="link" href="https://ifttt.com/withings" title="Withings Channel - IFTTT"
target="_blank" rel="noopener"
>great Withings support&lt;/a> allowing me to push my weight to various other web services.&lt;/p>
&lt;p>One IFTTT rule I have appends my weight to a text file in Dropbox. This file looks like this:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">263.86 August 21, 2014 at 05:56AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">264.62 August 22, 2014 at 08:27AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">264.56 August 23, 2014 at 09:41AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">263.99 August 24, 2014 at 08:02AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">265.64 August 25, 2014 at 08:08AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">267.4 August 26, 2014 at 08:16AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">265.25 August 27, 2014 at 09:08AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">264.17 August 28, 2014 at 07:21AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">264.03 August 29, 2014 at 08:43AM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">262.71 August 30, 2014 at 08:47AM
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>For a few months, I have been experimenting with using this time series to give myself a less-noisy update on my weight, and I&amp;rsquo;ve come up with a decent solution.&lt;/p>
&lt;p>This &lt;a class="link" href="http://www.r-project.org/" target="_blank" rel="noopener"
>R script&lt;/a> will take my weight time series, resample it, smooth it with a rolling median over the last month, and write summary stats to a text file in my Dropbox. It&amp;rsquo;s not the prettiest script, but it gets the job done for now.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-R" data-lang="R">&lt;span class="line">&lt;span class="cl">&lt;span class="n">INPUT_PATH&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="s">&amp;#34;~/Dropbox/Text Notes/Weight.txt&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">OUTPUT_PATH&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="s">&amp;#34;~/Dropbox/Text Notes/Weight Stats.txt&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lubridate&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ggplot2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">zoo&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># READ FILE&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">con&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">INPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;rt&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">lines&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">readLines&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">con&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">close&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">con&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># PARSE INTO LISTS OF WEIGHTS AND DATES&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">parse.line&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="kr">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">line&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">s&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">strsplit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">line&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">split&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">[[1]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">date.str&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s[2&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="m">10&lt;/span>&lt;span class="n">][&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="nf">is.na&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s[2&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="m">10&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">collapse&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">date&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">mdy_hm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">date.str&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quiet&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">l&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">as.numeric&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s[1]&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">date&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">names&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;weight&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">l&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">list.weight.date&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">lapply&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lines&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">parse.line&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">weights&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">lapply&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list.weight.date&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kr">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">X&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">X&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dates&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">lapply&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list.weight.date&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kr">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">X&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">X&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">date&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># BUILD DATA FRAME&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">df&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">data.frame&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">weight&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">unlist&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">weights&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">date&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">do.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;c&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dates&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># CREATE TIME SERIES AND RESAMPLE&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ts&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">zoo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">df&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">date&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ts&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">aggregate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nf">time&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">tail&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">g&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">round&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">seq&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">start&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="nf">end&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="m">60&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="m">60&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="m">24&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="s">&amp;#34;days&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ts&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">na.approx&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">xout&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># FUNCTION TO GET WEIGHT N-DAYS AGO IF WEIGHT IS SMOOTHED BY ROLLING MEDIAN&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># OVER A GIVEN (smooth.n) NUMBER OF DAYS&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">days.ago&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="kr">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">days&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">smooth.n&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">date&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">head&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">tail&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">index&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="n">days&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="m">1&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">smoothed&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">rollmedianr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">smooth.n&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">as.numeric&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">smoothed[date]&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># SMOOTH WEIGHT BY 29 DAYS AND GENERATE SOME SUMMARY STATS&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">days&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">29&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">current.weight&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">days.ago&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">days&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">current.weight&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current.weight&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nf">days.ago&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">days&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current.weight&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nf">days.ago&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">days&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current.weight&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nf">days.ago&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">365&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">days&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current.weight&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nf">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">round&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">names&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;current&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;7days&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;30days&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;365days&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;max&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fileConn&lt;/span>&lt;span class="o">&amp;lt;-&lt;/span>&lt;span class="nf">file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Weight (lbs):&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x[&lt;/span>&lt;span class="s">&amp;#34;current&amp;#34;&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Total Δ:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x[&lt;/span>&lt;span class="s">&amp;#34;max&amp;#34;&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;1 Week Δ:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x[&lt;/span>&lt;span class="s">&amp;#34;7days&amp;#34;&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;1 Month Δ:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x[&lt;/span>&lt;span class="s">&amp;#34;30days&amp;#34;&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">paste&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;1 Year Δ:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x[&lt;/span>&lt;span class="s">&amp;#34;365days&amp;#34;&lt;/span>&lt;span class="n">]&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">writeLines&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">fileConn&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">close&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fileConn&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The output looks something like this:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Weight (lbs): 265.7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Total Δ: -112
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 Week Δ: -0.8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 Month Δ: -4.8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 Year Δ: -75
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I want this script to be run every time my weight is updated, so I created a second IFTTT rule that will create a new file in my Dropbox, called &lt;em>new_weight_measurement&lt;/em>, every time I weigh in. On my Mac Mini, I have a &lt;a class="link" href="http://www.noodlesoft.com/hazel.php" title="Noodlesoft | Hazel"
target="_blank" rel="noopener"
>Hazel&lt;/a> rule to watch for a file of this name to be created. When Hazel sees the file, it runs my R script and deletes that file.&lt;/p>
&lt;p>My Hazel rule looks like this:&lt;/p>
&lt;figure>&lt;img src="https://tdhopper.com/uploads/2014/08/hazel-weight-1.png">
&lt;/figure>
&lt;p>The &amp;rsquo;embedded script&amp;rsquo; that is run is the R script above; I just have to tell Hazel to use the &lt;code>Rscript&lt;/code> shell.&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;figure>&lt;img src="https://tdhopper.com/uploads/2014/08/r-script-from-hazel.png">
&lt;/figure>
&lt;p>At this point, every time I step on my scale, a text file with readable statistics about my smoothed weight appear in my Dropbox folder.&lt;/p>
&lt;p>Of course, I want this updated information to be pushed directly too me. Hazel is again the perfect tool for the job. I have a second Hazel rule that watches for &lt;em>Weight Stats.txt&lt;/em> to be created. Hazel can pass the path of the updated file into any script of your choice. You could, for example, use &lt;a class="link" href="http://www.mailgun.com/" title="Transactional Email API Service for Developers - Mailgun"
target="_blank" rel="noopener"
>Mailgun&lt;/a> to email it to yourself or &lt;a class="link" href="https://pushover.net/" title="Pushover: Simple Notifications for Android, iOS, and Desktop"
target="_blank" rel="noopener"
>Pushover&lt;/a> to push it to your mobile devices. Obviously, I want to tweet mine.&lt;/p>
&lt;p>I have a Twitter account called &lt;a class="link" href="https://twitter.com/hopsfitness" target="_blank" rel="noopener"
>@hopsfitness&lt;/a> where I&amp;rsquo;ve recently been tracking my fitness progress. On my Mac Mini, I have &lt;a class="link" href="https://github.com/sferik/t" title="t GitHub"
target="_blank" rel="noopener"
>t&lt;/a> configured to access @hopsfitness from the command line. Thus, tweeting my updated statistics is just a matter of a little shell script executed by Hazel:&lt;/p>
&lt;figure>&lt;img src="https://tdhopper.com/uploads/2014/08/hazel-weight-2.png">
&lt;/figure>
&lt;p>Since this data goes to Twitter, I can get it painlessly pushed to my phone: Twitter still allows you subscribe to accounts via text message, which I&amp;rsquo;ve done with @hopsfitness. A minute or so after I step on my scale, I get a text with useful information about where I am and where I&amp;rsquo;m going; this is much preferable to the noisy weight I see on my scale.&lt;/p>
&lt;p>&lt;strong>Update&lt;/strong> (2014-12-06): I replaced my R script with a Python/pandas script. It requires Python 3 (to render the delta characters).&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">dateutil&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">pandas&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">pd&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">random&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">os.path&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">expanduser&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">join&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">home&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">expanduser&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;~&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">home&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;Dropbox/Text Notes/Weight.txt&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="s2">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readlines&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">parse_line&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">line&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">s&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">line&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">weight&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">date&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dateutil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parse&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39; &amp;#39;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">date&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weight&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">weight&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DataFrame&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">parse_line&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">l&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">lines&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">columns&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;weight&amp;#34;&lt;/span>&lt;span class="p">])&lt;/span> \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">set_index&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">resample&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;1D&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">how&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;mean&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">weight&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;missing&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">isnull&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">interpolate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">method&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;linear&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">std&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">diff&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dropna&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">std&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">noise&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">missing&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">missing&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">normalvariate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">std&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">missing&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">noise&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">smoothed&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ewma&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">span&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">current&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">smoothed&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">stats&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">Weight (lbs): &lt;/span>&lt;span class="si">%(weight).1f&lt;/span>&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">Total Δ: &lt;/span>&lt;span class="si">%(total).1f&lt;/span>&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">1 Week Δ: &lt;/span>&lt;span class="si">%(week).1f&lt;/span>&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">1 Month Δ: &lt;/span>&lt;span class="si">%(month).1f&lt;/span>&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">1 Year Δ: &lt;/span>&lt;span class="si">%(year).1f&lt;/span>&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">strip&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;weight&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">current&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;total&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">current&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">smoothed&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;week&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">current&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">smoothed&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;month&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">current&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">smoothed&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;year&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">current&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">smoothed&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">366&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">home&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;Dropbox/Text Notes/Weight Stats.txt&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="s2">&amp;#34;wb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">bytes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stats&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;UTF-8&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>This assumes your input file is formatted like mine, but you could easily adjust the first part of the code for other formats.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>You can &lt;a class="link" href="http://www.r-project.org/" title="The R Project for Statistical Computing"
target="_blank" rel="noopener"
>download R here&lt;/a>; installing it should add &lt;code>Rscript&lt;/code> to your system path.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Keeping IPython Notebooks Running in the Background</title><link>https://tdhopper.com/blog/keeping-ipython-notebooks-running-in-the-background/</link><pubDate>Thu, 28 Aug 2014 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/keeping-ipython-notebooks-running-in-the-background/</guid><description>&lt;p>I spend a lot of time in &lt;a class="link" href="http://ipython.org/notebook.html" title="The IPython Notebook &amp;amp;mdash; IPython"
target="_blank" rel="noopener"
>IPython Notebooks&lt;/a> for work. One of the few annoyances of IPython Notebooks is that they require keeping a terminal window open to run the notebook server and kernel. I routinely launch a Notebook kernel in a directory where I keep my work related notebooks. Earlier this week, I started to wonder if there was a way for me to keep this kernel running all the time &lt;em>without&lt;/em> having to keep a terminal window open..&lt;/p>
&lt;p>If you&amp;rsquo;ve ever tried to do chron-like automation on OS X, you&amp;rsquo;ve surely come across &lt;a class="link" href="http://launchd.info/" target="_blank" rel="noopener"
>launchd&lt;/a>, &amp;ldquo;a unified, open-source service management framework for starting, stopping and managing daemons, applications, processes, and script&amp;rdquo;. You&amp;rsquo;ve probably also gotten frustated with launchd and given up.&lt;/p>
&lt;p>I recently started using &lt;a class="link" href="http://www.soma-zone.com/LaunchControl/" title="soma-zone: LaunchControl"
target="_blank" rel="noopener"
>LaunchControl&lt;/a> &amp;ldquo;a fully-featured launchd GUI&amp;rdquo; for launchd; it&amp;rsquo;s pretty nice and worth $10. It occurred to me that LaunchControl would be a good way to keep my Notebook kernel running in the background.&lt;/p>
&lt;p>I created a LaunchControl to run the following command.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">/usr/local/bin/IPython notebook --matplotlib inline --port=9777 --browser=false
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This launches an IPython Notebook kernel accessible on port 9777; setting the browser flag to something other than an installed browser prevents a browser window from opening when the kernel is launch.&lt;/p>
&lt;p>I added three other launchd keys in LaunchControl:&lt;/p>
&lt;ul>
&lt;li>A &lt;em>Working Directory&lt;/em> key to tell LaunchControl to start my notebook in my desired folder.&lt;/li>
&lt;li>A &lt;em>Run At Load&lt;/em> key to tell it to start my kernel as soon as I load the job.&lt;/li>
&lt;li>And a &lt;em>Keep alive&lt;/em> key to tell LaunchControl to restart my kernel should the process ever die.&lt;/li>
&lt;/ul>
&lt;p>Here&amp;rsquo;s how it looks in LaunchControl:&lt;/p>
&lt;figure>&lt;img src="https://tdhopper.com/uploads/2014/08/launchcontrol.png">
&lt;/figure>
&lt;p>After I created it, I just had to save and load, and I was off to the races; the IPython kernel starts and runs in the background. I can access my Notebooks by navigating to 127.0.0.1:9777 in my browser. Actually, I added &lt;code>127.0.0.1 parsely.scratch&lt;/code> to my hosts file so I can access my Notebooks at parsely.scratch:9777. This works nicely with Chrome&amp;rsquo;s autocomplete feature. I&amp;rsquo;m avoiding the temptation to run nginx and give it an even prettier url.&lt;/p></description></item><item><title>Introduction to Scikit-Learn</title><link>https://tdhopper.com/blog/scikit/</link><pubDate>Mon, 21 Jan 2013 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/scikit/</guid><description>&lt;p>I gave a talk at a recent Research Triangle Analysts meetup on scikit-learn, the excellent machine learning library for Python. You can see the &lt;a class="link" href="http://nbviewer.jupyter.org/format/slides/github/tdhopper/Research-Triangle-Analysts--Intro-to-scikit-learn/blob/master/Intro%20to%20Scikit-Learn.ipynb" target="_blank" rel="noopener"
>IPython notebook that I presented from&lt;/a>.&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/2kx19t8bNMU"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div></description></item><item><title>Pickle and Redis</title><link>https://tdhopper.com/blog/pickle-and-redis/</link><pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate><guid>https://tdhopper.com/blog/pickle-and-redis/</guid><description>&lt;p>I gave a talk at PyCarolinas 2012 about using Pickle and Redis to persist data with Python. It wasn&amp;rsquo;t recorded, but you can [see the IPython notebook I presented from](&lt;a class="link" href="http://nbviewer.jupyter.org/github/tdhopper/Pickle-and-Redis/" target="_blank" rel="noopener"
>http://nbviewer.jupyter.org/github/tdhopper/Pickle-and-Redis/&lt;/a>
blob/master/Pickle%20and%20Redis.ipynb).&lt;/p></description></item></channel></rss>