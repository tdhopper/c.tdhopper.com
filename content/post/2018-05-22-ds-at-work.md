---
title: "I Basically Can't Hire People Who Don't Know Git"
categories:
    - Quote
tags: []
slug: data-scientists-at-work
date: 2018-05-22
description: Dr. Eric Jonas on data science and software engineering.
draft: false
---

In 2014, [Sebastian Gutierrez](https://twitter.com/seb_g) published a collection of interviews entitled [Data Scientists at Work](https://amzn.to/2Lo0A7s). My friend and former boss Eric Jonas posted [his interview on his website](http://ericjonas.com/datascientistsatwork.html). It's full of gems.

On engineering skills required for data science work, Eric says,

> On the industry side, I think that the ability to do software engineering is something that is very important, but isn’t really taught. You don’t actually learn it as a computer science undergraduate, and you certainly don’t learn it as a graduate student. So for me it’s very important that someone has learned it somehow—either by themselves or from someone else. __I basically can’t hire people who don’t know Git.__

On someone trained in pure mathematics learning to analysis of real-world data, Eric says:

> ...data analysis is so much messier than actual math. I have friends who work on these topology-based approaches, and I’m like, “You realize these manifolds totally evaporate when you actually throw noise into the system. How do you think this is really going to play out here?” So I would much rather someone be computationally skilled. I’m willing to trade off what their Putnam score was for how many open source GitHub projects they’ve committed to in the past.

I tried to argue this same point in [an earlier post](/how/).

On applying academic research, Eric observes:

> For example, when I evaluate machine learning papers, what I am looking to find out is whether the technique worked or not. __This is something that the world needs to know—most papers don’t actually tell you whether the thing worked.__ It’s really infuriating because most papers will show five dataset examples and then show that they’re slightly better on two different metrics when comparing against something from 20 years ago. In academia, it’s fine. In industry, it’s infuriating, because you need to know what actually works and what doesn’t.

I have suggested before that we need a good website for sharing implementations of academic algorithms and providing a forum for discussion of whether or not the algorithm _actually works_.

I highly recommend reading Eric's [full interview](http://ericjonas.com/datascientistsatwork.html).
